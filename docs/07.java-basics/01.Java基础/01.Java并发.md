---
title: 01.Java并发编程
date: 2024-04-01 16:41:33
permalink: /pages/9eee62
---



## 线程的状态以及状态之间的转换

线程的状态有 6 种：新建 New、就绪 Ready、运行中 Running、阻塞 Blocker、超时等待 Timed Waiting、退出 Terminated

接下来说一下各个状态之间如何转变：

![image-20240229124706730](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240229124706730.png)



**接下来说一下上边出现的方法的含义：**

- **wait() 和 sleep()：**

wait() 来自 Object 类，会释放锁

sleep() 来自 Thread 类，不会释放锁

上边图中的 wait() 是有一个时间的，在指定时间内让线程进行等待，但是在实际使用中，**一般是将 `wait()` 和 `notify()/notifyAll()` 配合进行使用的**  

`wait()` 方法让当前线程进行等待也就是让线程停止执行，`notify()` 方法让已经被 wait() 方法停止的线程继续执行

不过使用 `wait()` 有一个条件：已经获取锁的线程才可以调用 `wait()` 方法，也就是 `wait()` 必须写在 `synchronized` 代码块中

```java
Object obj = new Object();
synchronized (obj) {
	this.wait();
}
```



**`notify()` 和 `notifyAll()` 方法的区别：**

1、`notify()` 会随机唤醒等待队列中的一个线程，特点就是随机唤醒，并且只唤醒一个线程

2、`notifyAll()` 会唤醒等待队列中的所有线程



- **interrupt()**

用于停止线程，给线程发出一个中断信号，但是并不会立即中断，会设置线程的中断标志位为 true

一般停止线程都会使用 interrupt() 方法，但是这个方法并不会立即中断正在运行的线程，**想要立即停止线程** ，可以使用 sleep() 和 interrupt() 搭配使用：

从下边输出可以看到，当子线程 sleep() 时，我们在 main 线程中调用子线程的 interrupt()，那么子线程就会抛出 InterruptedException（只要 sleep() 和 interrupt() 方法碰到一起，就一定会抛出异常，我们可以使用抛出异常的方法，**来优雅的停止线程的执行** ）

```java
public static void main(String[] args) {
    try {
        Thread thread = new Thread(()->{
            try {
                // 让子线程先 sleep
                System.out.println("run begin");
                Thread.sleep(2000);
                System.out.println("run end");
            } catch (InterruptedException e) {
                System.out.println("子线程 sleep 过程中被 interrupt，导致抛出 InterruptedException");
                e.printStackTrace();
            }
        });
        thread.start();
        // 让主线程等子线程启动起来
        Thread.sleep(200);
        // 调用子线程的 interrupt()
        thread.interrupt();
    } catch (InterruptedException e) {
        System.out.println("主线程捕获中断异常");
    }
    System.out.println("end");
}

// 程序输出
run begin
end
子线程 sleep 过程中被 interrupt，导致抛出 InterruptedException
java.lang.InterruptedException: sleep interrupted
	at java.lang.Thread.sleep(Native Method)
	at com.alibaba.craftsman.command.PaperMetricAddCmdExe.lambda$main$0(PaperMetricAddCmdExe.java:42)
	at java.lang.Thread.run(Thread.java:748)

```

- **yield()**

通过 `yield()` 会让线程从运行态到 `就绪态` 

`yield()` ：让当前线程放弃对 cpu 的占用，放弃多长时间不确定，有可能刚刚放弃，马上又获得了 cpu 的时间片



- **join()**

用于阻塞等待另一个线程执行完毕

比如 A 线程中调用了 B 线程的 `join()` 方法，那么 A 就会等待 B 线程执行完毕之后，再执行继续执行 A 线程之后的方法

```java
public static void main(String[] args) {
    try {
        MyThread thread = new MyThread();
        thread.start();
        // 主线程等待子线程运行完毕
        thread.join();
        System.out.println("主线程等待子线程运行完毕，再执行后来的操作");
    } catch (InterruptedException e) {
        e.printStackTrace();
    }
}
```

- **LockSupport.park()/unpark()**

`LockSupport` 是 JUC 工具包中的 `基本线程阻塞原语` ，给 AQS（抽象队列同步器） 提供了阻塞、唤醒线程的能力

`LockSupport.park()` 用于阻塞当前线程，可以通过另一个线程调用 `LockSupport.unpark(Thread)` 方法来唤醒指定线程

LockSupport 是基于 Unsafe 实现，不需要获取对象的监视器，只需要给线程设置 permit 许可，每个线程只会拥有 1 个或 0 个 permit 许可





- **扩展：说一下 notify() 和 wait() 怎么使用**

`wait()` 和 `notify()` 是线程之间通信比较重要的一种手段，因此要好好掌握一下

首先 wait() 和 notify() 针对的是拿到了同一把锁的线程，这两个方法都要在 `synchronized` 同步代码块中执行，也就是线程必须先拿到锁之后，才能执行这两个方法，否则会抛出 `IllegalMonitorStateException` 异常

接下来通过一个示例来讲解一下 notify() 和 wait() 具体如何使用，两个线程交替打印数字，这个问题在面试的时候也有考察，主要是查看是否熟悉多线程

**代码放在下边了，这里稍微解释一下代码**

1、首先两个线程的 run 方法中是一个 while 死循环，来保证可以持续打印数字，直到 100

2、线程 A 打印偶数，因此当线程 A 发现 `i % 2 == 1` ，也就是 i 为奇数，就调用锁对象的 wait 方法，即`twoThread.wait()` （这里要 `注意` 的就是 synchronized 对哪个对象加锁，就要调用哪个对象的 wait() 和 notify() 方法）

3、线程 A 执行 wait() 方法之后，就释放锁，线程 B 拿到锁之后进入 synchronized 代码块进行执行，发现 i 为奇数，于是输出，并且调用 `twoThread.notify()` 方法，来唤醒线程 A，线程 B 执行完 `notify()` 之后退出了同步代码块，线程 A 被唤醒就拿到了锁，从 wait() 之后继续执行

```java
public class TwoThread {
    volatile int i = 0;

    public static void main(String[] args) {
        TwoThread twoThread = new TwoThread();
        twoThread.test();
    }
    public void test() {
        TwoThread twoThread = new TwoThread();
        String obj = new String();
        new Thread(() -> {
            while (twoThread.i < 100) {
                synchronized (twoThread) {
                    if (twoThread.i % 2 == 1) {
                        try {
                            twoThread.wait();
                        } catch (InterruptedException e) {
                            throw new RuntimeException(e);
                        }
                    }
                    System.out.println(Thread.currentThread().getName() + ":" + twoThread.i++);
                    twoThread.notify();
                }

            }
        }, "A").start();
        new Thread(() -> {
            while (twoThread.i < 100) {
                synchronized (twoThread) {
                    if (twoThread.i % 2 == 0) {
                        try {
                            twoThread.wait();
                        } catch (InterruptedException e) {
                            throw new RuntimeException(e);
                        }
                    }
                    System.out.println(Thread.currentThread().getName() + ":" + twoThread.i++);
                    twoThread.notify();
                }

            }
        }, "B").start();
    }
}
```





## 面试：了解 ThreadLocal 内存泄漏需要满足的 2 个条件吗？

### 什么是 ThreadLocal？

ThreadLocal 用于存储线程本地的变量，如果创建了一个 ThreadLocal 变量，在多线程环境下访问这个变量的时候，每个线程都会在自己线程的本地内存中创建一份变量的副本，从而起到 **线程隔离** 的作用



### Thread、ThreadLocal、ThreadLocalMap 之间的关系

<img src="https://11laile-note-img.oss-cn-beijing.aliyuncs.com/1706850199755.png" alt="1706850199755" style="zoom:80%;" />

每一个`Thread`对象均含有一个`ThreadLocalMap`类型的成员变量`threadLocals`，它存储本线程所有的 ThreadLocal 对象及其对应的值

`ThreadLocalMap`由一个个的`Entry<key,value>`对象构成，Entry继承自`weakReference<ThreadLocal<?>>`，一个`Entry`由`ThreadLocal`对象和`Object`构成

- Entry 的 key 是ThreadLocal对象，并且是一个弱引用。当指向key的强引用消失后，该key就会被垃圾收集器回收
- Entry 的 value 是对应的变量值，Object 对象

当执行set方法时，ThreadLocal首先会获取当前线程 Thread 对象，然后获取当前线程的ThreadLocalMap对象，再以当前ThreadLocal对象作为key，设置对应的 value。

由于每一条线程均含有各自私有的 ThreadLocalMap 对象，这些容器相互独立互不影响，因此不会存在线程安全性问题，从而也就无需使用同步机制来保证多条线程访问容器的互斥性



### ThreadLocal 使用场景

1、在进行对象跨层传递的时候，使用ThreadLocal可以避免多次传送，打破层次间的约束。

> 即如果一个User对象需要从Controller层传到Service层再传到Dao层，那么把User放在ThreadLocal中，每次使用ThreadLocal来进行获取即可

2、线程间数据隔离

3、进行事务操作，用于存储线程事务信息

4、数据库连接，Session会话管理



### ThreadLocal 的内存泄漏问题

**先说一下什么情况下会发生内存泄漏，需要满足 2 个条件：**

- 线程内部的 ThreadLocalMap 存储的数据一直未被清理
- 线程持续存活（线程处在线程池中），导致线程内部的 ThreadLocalMap 对象一直未被回收

接下来说一下什么时候，会符合上边的两个条件，首先对于 **第一个条件** 来说，有两种情况：ThreadLocal 定义为局部变量、ThreadLocal 定义为全局静态变量

#### ThreadLocal 被定义为局部变量

当 ThreadLocal 被定义为方法中的 **局部变量** ，那么当线程进入该方法的时候，就会将 ThreadLocal 的引用给加载到线程的 **栈** 中

如下图所示，在线程栈 Stack 中，有两个变量，ThreadLocalRef 和 CurrentThreadRef，分别指向了声明的局部变量 ThreadLocal ，以及当前执行的线程内部的 ThreadLocalMap 变量

![image-20241019135606046](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20241019135606046.png)

当线程执行完该方法之后，就会将该方法局部变量从栈中删除，因此Stack 线程栈中的 ThreadLocalRef 变量就会被弹出栈，因此 ThreadLocal 变量的强引用消失了，那么 ThreadLocal 变量只有 Entry 中的 key 对他引用，并且还是弱引用，因此这个 ThreadLocal 变量会被垃圾回收器给回收掉，导致 Entry 中的 key 为 null，而 value 还指向了对 Object 的强引用，因此 value 还一直存在 ThreadLocalMap 变量中，如下图：

![image-20241019140113170](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20241019140113170.png)

此时可以看到，ThreadLocalMap 内部 Entry 的 key（ThreadLocal）为 null，因此无法通过 key 去访问到这个 value，导致这个 value 一直无法被回收

因此 JDK 设计者在设计 ThreadLocal 时还添加了清除 ThreadLocalMap 中 key 为 null 的 value，避免内存泄漏，这是在设计时为了避免内存泄漏而采取的措施，而我们使用的时候要保持良好的编程规范，也要手动去 remove，避免内存泄漏的发生



#### ThreadLocal 被定义为全局静态变量

如果定义 ThreadLocal 为 `private static final` ，那么这个 ThreadLocal 就会在常量池中存储，而不是存储在堆中，因此 ThreadLocal 并不会被回收，也就不会出现 ThreadLocalMap 的 Entry 中 key == null 的情况

这时候要考虑的问题是当前线程在使用完 ThreadLocal 之后要主动 remove，避免数据一直存储在对应的 ThreadLocalMap 中，从而出现脏数据以及内存泄漏





**接下来说一下发生内存泄漏需要满足的第二个条件：线程持续存活**

在梳理第一个条件（ThreadLocalMap 中的数据未被清理）时，有两种情况，一种是 ThreadLocal 被定义为局部变量，另一种是 ThreadLocal 被定义为全局静态变量

- 当 ThreadLocal 被定义为局部变量时，会出现 ThreadLocalMap 中 key == null 的情况，在 JDK 内部会主动清理 key == null 的value，因此这种情况不会出现内存泄漏

- 当 ThreadLocal 被定义为全局静态变量时，此时 ThreadLocalMap 内部的 key 永远不会被回收，因此如果使用之后不手动 remove 对应变量，就会导致对应的值一直存活在当前线程中，如果此时再满足第二个条件 **线程持续存活** ，就会导致对应的值一直不会被回收，出现内存泄漏



当使用 **线程池** 执行任务时， **核心线程会一直存活** ，就会导致该线程内部的 ThreadLocalMap 变量不会清理，从而导致对应的数据一直在内存中存活， **出现内存泄漏问题** ，因此在使用 ThreadLocal 时一定要遵守正确的使用规范，避免出现内存泄漏



### ThreadLocal 使用规范

**ThreadLocal 正确的使用方法：**

- 将 ThreadLocal 变量定义成 private static final，这样就一直存在 ThreadLocal 的强引用，也能保证任何时候都能通过 ThreadLocal 的访问到 Entry 的 value 值，进而清除掉
- 每次使用完 ThreadLocal 都调用它的 remove() 方法清除数据

下面给出 ThreadLocal 的用法：

```java
public class ThreadLocalExample {
    private static final ThreadLocal<Integer> counter = new ThreadLocal<Integer>() {
        @Override
        protected Integer initialValue() {
            return 0;
        }
    };

    public static void main(String[] args) {
        Thread t1 = new Thread(() -> {
            try {
                int value = counter.get(); // 获取当前线程的副本值
                counter.set(value + 1); // 修改副本值
                System.out.println("Thread " + Thread.currentThread().getName() + " value: " + counter.get());
            } finally {
                // 手动移除
                counter.remove(); // 在线程结束时移除变量
            }
        });

        Thread t2 = new Thread(() -> {
            try {
                int value = counter.get();
                counter.set(value + 1);
                System.out.println("Thread " + Thread.currentThread().getName() + " value: " + counter.get());
            } finally {
                // 手动移除
                counter.remove();
            }
        });

        t1.start();
        t2.start();
    }
}
```







## JDK 下的高性能计数器 LongAdder 实现原理

**为什么要看 JDK 的并发源码包下的代码呢？**

在真实场景中，并发不可避免，因此需要对并发访问的临界资源进行加锁控制来保证数据安全，在保证安全的基础上，为了进一步提升并发的性能，通常要做很多性能优化，在分布式环境的性能优化，就比如 Redis 加锁，将加锁的粒度缩小来提升并发度，理论是这样一个理论，但是具体学习练手的话，通常要集成 Redis、MySQL 等较多组件，并且没有一个很规范的最佳实践。

基于这两个问题，可以研究 JDK 的并发源码包，它内部有很多提升性能的手段，比如接下来要讲的 LongAdder 中为了提升性能去减少锁粒度，具体如何解决，并且如何通过 CAS 乐观锁代替悲观锁，在 JUC 源码包下不仅有理论，更有 **Doug Lea（Java 并发包作者）** 的最佳实践，为学习并发保驾护航！

接下来主要介绍 JUC 下的 AtomicLong 的实现，以及比它性能更好的 LongAdder 的实现原理！

### AtomicLong 实现原理

#### 作用

AtomicLong 用来存储一个 long 型数据，并且可以保证多线程场景下的并发安全



#### 结构组成

AtomicLong 属性主要有两个：valueOffset 和 Unsafe 实例

- valueOffset：记录了存储的 value 值在内存中的偏移量（在静态代码块中初始化）
- unsafe：获取了 Unsafe 实例，通过它提供的 CAS 操作直接写内存，保证无锁下状态下的并发安全（Unsafe 只能在 JDK 包里使用，不允许开发者使用）

```JAVA
public class AtomicLong extends Number implements java.io.Serializable {
    // 1、Unsafe 操作实例
    private static final Unsafe unsafe = Unsafe.getUnsafe();
    // 2、存储的 value 值在内存中的偏移量
    private static final long valueOffset;
    // 3、存储的 value 值，通过 volatile 保证线程之间可见
    private volatile long value;

    static {
        try {
            // 4、在静态代码块中初始化 value 值对应的内存偏移量
            valueOffset = unsafe.objectFieldOffset
                (AtomicLong.class.getDeclaredField("value"));
        } catch (Exception ex) { throw new Error(ex); }
    }
}
```



#### 并发操作

AtomicLong 内部提供了多种操作，这里只看常用的几种操作：

- set()
- compareAndSet()
- incrementAndGet()



**set() 操作：**

set 操作直接赋值实现，因为 value 值通过 volatile 来保证该值在多线程之间的可见性，因此可以直接修改

```JAVA
public final void set(long newValue) {
    value = newValue;
}
```



**compareAndSet() 操作：**

通过比较当前值和预期值是否相等，如果相等再去设置新的值，这里是通过 Unsafe 来直接操作内存实现的，因此这里用到了在静态代码块中初始化的偏移量（valueOffset），根据偏移量去内存直接找到该值进行比较和赋值

```JAVA
public final boolean compareAndSet(long expect, long update) {
    return unsafe.compareAndSwapLong(this, valueOffset, expect, update);
}
```



**incrementAndGet() 操作：**

在 Java 中，`i ++` 操作是不安全的，因为在字节码层面是分为了两个步骤：先获取值、再更新值，因此整体不属于原子操作

在 AtomicLong 中为了保证他的原子性，也是通过 Unsafe 执行 CAS 操作来实现的

```JAVA
public final long incrementAndGet() {
    return unsafe.getAndAddLong(this, valueOffset, 1L) + 1L;
}
```



**AtomicLong 总结：**

- 内部核心数据结构包括：value、valueOffset、Unsafe 实例
- 并发安全是通过 CAS 来保证



### LongAdder

在 AtomicLong 中，通过 CAS 去保证并发安全，但是如果竞争比较激烈的话，性能还是会较差，比如一个 AtomicLong 记录值，多个线程同时进行 CAS 操作，那就会出现大量线程竞争，那么 CAS 在竞争激烈的情况下性能表现是很不好的，因此 LongAdder 对他进一步进行优化，接下来一步一步学习 Doug Lea 大师的优化思路！

LongAdder 是 JDK1.8 出的原子类，性能比 AtomicLong 更强，先分析 AtomicLong 为什么性能弱？

![image-20241022153042902](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20241022153042902.png)



在 AtomicLong 中，通过一个 value 值进行存储，那么所有线程同时来竞争 value 这把锁，那么想要提升性能，要怎么做呢？

答案就是将 value 拆开，将 value 值拆成多个值，这样的话，多个线程会分别竞争不同的锁，因此竞争激烈程度下降，并发性能得到提升

![image-20241022153850641](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20241022153850641.png)

> 扩展：可以发现，大多数提升性能的思想都是类似的，在 Redis 为了减少锁的竞争，也是去设计分布式锁的 key，减少锁的粒度



#### LongAdder 并发优化

接下来可以带着这几个问题去看 LongAdder 是如何进行优化的：

- 如何将一个 value 分散为多个 value？
- 统计 value 值的时候，是否会阻塞所有线程对各个 value 进行操作？
- 每个线程如何选择自己要操作的 value？



#### LongAdder 内部属性

LongAdder 继承自 Striped64（Striped64主要用于支持并发累加器的实现。这个类在高并发环境下被用来做某种计数，其设计的核心思想是在竞争激烈的时候尽量分散竞争）

**LongAdder 实现原理：** LongAdder 实现了高性能的累加器，他将一个数分散在了 base 和 cells 数组上，分散锁的竞争，将 base 值加上所有 cells 数组的值即为 LongAdder 记录的值

LongAdder 内部的 3 个属性来自于 Striped64 类：

- base：`volatile` 修饰的 long 类型的基础值， 
- cells：`Cell[]` 类型的数组
- cellsBusy：`volatile int` 类型，用来实现自旋锁，保证只有一个线程在进行扩容或初始化 Cell 数组的操作

LongAdder 内部提供了核心方法： add() 方法，因此来看 add() 方法内部如何实现多线程环境下的安全：

```JAVA
public void add(long x) {
    Cell[] as; long b, v; int m; Cell a;
    // 1、初步判断
    if ((as = cells) != null || !casBase(b = base, b + x)) {
        boolean uncontended = true;
        // 2、进一步判断
        if (as == null || (m = as.length - 1) < 0 ||
            (a = as[getProbe() & m]) == null ||
            !(uncontended = a.cas(v = a.value, v + x)))
            longAccumulate(x, null, uncontended);
    }
}
```



先解释一下步骤（1）：

- 当初次调用 `add()` 方法时，内部 cells 数组为 null ，此时会直接通过 CAS 操作修改 base 变量的值
- 如果修改成功直接返回，return；
- 如果修改失败，说明 **多个线程存在竞争** ，此时会去进行步骤（2）的操作，之后 cells 数组初始化后就不是 null 了，因此步骤（1）中的 `(as = cells) != null` 直接为 true，就不再修改 base 值，而是去修改 cells 数组中的值了

再来看步骤（2），先解释 if 中的各个判断条件：

- `as == null` ：cells 数组为空，因此直接调用 longAccumulate 方法
- `m = (as.length - 1) < 0` ：如果 cells 数组初始化后，比如说 cells 数组长度为 4，那么计算后 m = 3，这里的 m 是用作之后的 **与操作(&)** 使用的
- `(a = as[getProbe() & m])` ：通过 `getProbe() & m` 获取该线程要操作的 cells 数组的下标，这里 getProbe() 就类似于每个线程的 Hash 值，通过线程的哈希值与之前计算得到的 m 进行 **与操作(&)** 来获取操作的 cells 数组下标
- `!(uncontended = a.cas(v = a.value, v + x))` ：如果通过 CAS 去修改 cells 数组对应的 Cell 数据失败了，也进入 longAccumulate 方法



**longAccumulate() 方法内容较多，因此我们只关注核心的地方：**

- （1）线程 CAS 操作 base 变量失败，进入 longAccumulate() 方法，此时会进行哪些操作？
- （2）线程 CAS 操作 cells 数组失败，进入 longAccumulate() 方法，此时会进行哪些操作？

先看（1），线程 CAS 操作 base 变量失败，此时说明 cells 数组还没有初始化，因此会初始化 cells：

```JAVA
for (;;) {
    Cell[] as; Cell a; int n; long v;
    // （1）初始化 cells 数组，通过 CAS 设置 cellsBusy 来保证只有一个线程操作
    else if (cellsBusy == 0 && cells == as && casCellsBusy()) {
        boolean init = false;
        try {                           
            if (cells == as) {
                // 初始化数组
                Cell[] rs = new Cell[2];
                // 数组赋值
                rs[h & 1] = new Cell(x);
                cells = rs;
                init = true;
            }
        } finally {
            // 释放锁
            cellsBusy = 0;
        }
        if (init)
            break;
    }                        
}
```

再看（2），CAS 操作 cells 数组失败，那么说明多个线程竞争了同一个 cells 数组的位置，因此重新对计算线程操作的 cells 数组下标，避免在同一个地方一直竞争

```JAVA
for (;;) {
    Cell[] as; Cell a; int n; long v;
    if ((as = cells) != null && (n = as.length) > 0) {
        
        // 1、如果 CAS 操作 cells 数组失败，那么 wasUncontended = false，因此这里设置为 true
        // 为什么要这样做呢？
        // 其实 wasUncontended 变量没有用处，只是避免走到其他的 if 分支
        // 当 wasUncontended 设置为 true 之后，通过 h = advanceProbe(h) 重新获取线程的 hash 值，换一个 cells 数组的位置进行操作
        else if (!wasUncontended)       // CAS already known to fail
            wasUncontended = true;      // Continue after rehash
        h = advanceProbe(h);
    }
```



#### 伪共享解决

在多线程环境下，解决伪共享问题可以大幅度提升并发性能，具体可见：[开源高性能无锁内存队列 Disruptor 解决伪共享问题](https://mp.weixin.qq.com/s/o6sXMwY7fgdHj7QbaqgvPQ)

cells 数组中的元素类型是 Cell，这里通过 JDK 的 `@Contended` 来解决伪共享问题，如下：

```JAVA
@sun.misc.Contended static final class Cell {
    volatile long value;
    Cell(long x) { value = x; }
    // ...
}
```





#### 总结

最后总结一下 LongAdder 做了哪些优化：

- 将 value 值分为了 base 变量和 cells 数组，分散锁的竞争
- 全程没有使用 synchronized、ReentrantLock 锁，通过 CAS 来实现并发安全
- 解决伪共享问题，避免多线程环境下的 CPU 缓存频繁失效问题





## 线上服务压测，如果压测标记丢失，如何解决？

这里介绍一个场景面试题，当线上服务压测时，如果使用 ThreadLocal 存储了压测流量标记，导致压测标记丢失，该如何解决？

接下来会介绍 ThreadLocal 存在的问题，以及对应的解决方案原理

### ThreadLocal 存在问题

通过一个具体场景进行介绍： **线上服务压测**

当需要线上服务压测时，需要通过压测标记来和真实的线上流量区分开，在真实场景中，服务之间会来回调用， **因此需要保证压测标记在传递过程中不会丢失** ，常见的做法是将压测标记放在 HTTP 请求的 header 中，在应用入口将标记存储在 ThreadLocal 里，当调用其他服务时，获取 ThreadLocal 里的压测标记，并且传递给其他服务，以此来实现 **压测标记在整个调用链路中的传递。** 

![image-20241027201909029](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20241027201909029.png)

**压测标记丢失后果：** 在进行线上服务压测时，如果压测标记丢失，后果很严重，这样无法区分真实流量和压测流量，导致线上出现大量脏数据，因此需要保证压测标记在整个链路中可以准确传递。

**压测标记传递手段：** 

如果通过 ThreadLocal 传递压测标记的话，在真实测试中发现，压测标记在传递过程发生了丢失，最后经排查发现，是因为异步调用其他服务，子线程没有继承父线程中 ThreadLocal 的值，导致压测标记丢失，因此有两种解决方案：

- **InheritableThreadLocal：** 当使用 `new Thread()` 方式创建线程时，使用 InheritableThreadLocal  可以让子线程继承父线程的变量
- **TransmittableThreadLocal：** 当使用 **线程池** 的方式执行异步任务时，使用 TransmittableThreadLocal 来完成父子线程的变量继承

其中 TransmittableThreadLocal 是 Alibaba 开源的，由于 InheritableThreadLocal 无法处理线程池的场景，因此 TransmittableThreadLocal 作为 InheritableThreadLocal 的扩展，可以处理线程池场景下的变量复制问题



### InheritableThreadLocal

InheritableThreadLocal 继承自 ThreadLocal，提供了子线程继承父线程值的功能，接下来看一下如何它内部如何实现

上边说了 InheritableThreadLocal 提供了异步创建线程时，子线程可以继承父线程值的功能，假如说我们想要去实现，需要怎么实现？

- **实现原理：** 既然是创建线程时，要让子线程继承父线程的功能，那么就必须修改创建线程的代码，也就是 Thread 类的构造方法

#### Thread 类改造

先来看一下 Thread 类中的对应的实现，Thread 类里有两个 ThreadLocal 相关的属性：

- threadLocals： 当前线程维护的 ThreadLocal 对应的值
- inheritableThreadLocals： 当前线程维护的 InheritableThreadLocal 对应的值

InheritableThreadLocal 实现了子线程继承父线程值的功能，因此，在创建线程时，判断父线程的 InheritableThreadLocal 值是否为空，如果不为空，就将对应的值复制给子线程即可，如下图所示：

```JAVA
class Thread implements Runnable {
    ThreadLocal.ThreadLocalMap threadLocals = null;
    ThreadLocal.ThreadLocalMap inheritableThreadLocals = null;

    // new Thread() 方法最终会走到 init() 方法内部
    private void init(/*参数较长，省略*/) {
    this.name = name;
    
    Thread parent = currentThread();
    // 这里判断父线程的 inheritableThreadLocals 如果不为空，就让子线程继承父线程的 inheritableThreadLocals 值
    if (inheritThreadLocals && parent.inheritableThreadLocals != null)
        this.inheritableThreadLocals =
            ThreadLocal.createInheritedMap(parent.inheritableThreadLocals);
	}
}
```



#### InheritableThreadLocal 改造

在 InheritableThreadLocal 中，继承了 ThreadLocal 类，只覆盖了 3 个方法，这里主要看一下 `createMap()` 方法：

- createMap() ：在该方法，将对应的值赋给了 Thread 的 inheritableThreadLocals，那么在创建异步线程时，就会判断该变量是否为空，不为空的话，就赋给子线程

```JAVA
public class InheritableThreadLocal<T> extends ThreadLocal<T> {

    protected T childValue(T parentValue) {
        return parentValue;
    }

    ThreadLocalMap getMap(Thread t) {
       return t.inheritableThreadLocals;
    }

    void createMap(Thread t, T firstValue) {
        t.inheritableThreadLocals = new ThreadLocalMap(this, firstValue);
    }
}
```





### TransmittableThreadLocal

TransmittableThreadLocal 是 Alibaba 开源的，由于 JDK 默认没有支持线程池场景下 ThreadLocal 继承的功能，因此 Alibaba 自己开源了一套出来，代码比较多，接下来只介绍核心实现原理：

对应 Maven 依赖如下：

```XML
<dependency>
    <groupId>com.alibaba</groupId>
    <artifactId>transmittable-thread-local</artifactId>
    <version>2.12.0</version>
</dependency>
```

相关代码结构如下：

<img src="https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20241027155213754.png" alt="image-20241027155213754" style="zoom:80%;" />



**如何改进？**

先思考一下，如果让我们自己去改造，该如何进行改造？

InheritableThreadLocal 是 JDK 内部提供的实现，因此他可以直接在 Thread 的构造方法中进行改造，但是我们作为普通开发者，肯定是没办法直接改造 JDK 代码

TransmittableThreadLocal 要实现的功能是线程池执行任务时，将父线程的 ThreadLocal 变量也赋值给子线程，因此线程池的 execute() 方法肯定需要变动，但是我们无法修改 JDK 内部的源码，因此可以通过另外一种方式：**装饰器模式** （装饰器模式可以在原有的功能上做增强）

基于原有线程池做一层装饰，在 `execute()` 方法中，不提交 JDK 内部的 Thread，而是去提交我们自己实现的 Thread，之后在执行 Thread 的 run  方法时，去复制父线程的变量，来达到父线程变量传递的目的，最后简单总结一下：

1、基于装饰器模式，对原有线程池的实现做包装

2、实现自定义的 Thread，在 run() 方法内部去做变量的赋值操作

整体结构如下图所示：

![image-20241027201343894](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20241027201343894.png)

#### 线程池改造

TransmittableThreadLocal 内对应的线程池包装如下，在执行 execute() 方法时，将原有的线程包装为了 `TtlRunnable`

```JAVA
class ExecutorTtlWrapper implements Executor, TtlWrapper<Executor>, TtlEnhanced {
    private final Executor executor;
    protected final boolean idempotent;

    public void execute(@NonNull Runnable command) {
        // 创建了 TtlRunnable 线程
        this.executor.execute(TtlRunnable.get(command, false, this.idempotent));
    }
	// ...
}
```



#### 线程改造

在 TtlRunnable 中，去获取父线程的变量快照，之后去执行对应的任务，这里获取父线程的变量快照方法被封装在了 Transmitter 工具类中

```JAVA
public final class TtlRunnable implements Runnable, TtlWrapper<Runnable>, TtlEnhanced, TtlAttachments {
    
    // 存储父线程变量的快照拷贝
    private final AtomicReference<Object> capturedRef;
    private final Runnable runnable;
    // 运行之后，是否需要释放 captureRef
    private final boolean releaseTtlValueReferenceAfterRun;

    private TtlRunnable(@NonNull Runnable runnable, boolean releaseTtlValueReferenceAfterRun) {
        // 通过 Transmitter # capture() 方法去拷贝对应变量，其实就是对 Map 进行复制
        this.capturedRef = new AtomicReference<>(capture());
        this.runnable = runnable;
        this.releaseTtlValueReferenceAfterRun = releaseTtlValueReferenceAfterRun;
    }

    @Override
    public void run() {
        // 1、获取父线程变量的快照（获取变量的方法封装在了 Transmitter 类中）
        final Object captured = capturedRef.get();
        // 这里 capturedRef 存储了父线程变量快照，如果需要释放的话，通过 CAS 将其释放
        if (captured == null || releaseTtlValueReferenceAfterRun && !capturedRef.compareAndSet(captured, null)) {
            throw new IllegalStateException("TTL value reference is released after run!");
        }
		// 2、保存当前父线程变量的副本
        final Object backup = replay(captured);
        try {
            // 3、执行线程任务
            runnable.run();
        } finally {
            // 4、恢复当前线程执行前的变量
            restore(backup);
        }
    }
}
```



**这里在 run() 方法中，为什么要恢复当前线程执行前的变量？**

一般情况下是不需要恢复的，但是如果线程池的拒绝策略为 **CallerRunsPolicy** ，当线程池满了之后，所有的任务都会交给主线程来执行，因此在这种情况下，在执行完任务之后，需要将当前线程的 ThreadLocal 变量进行复原











## 管程

Java 中提供的并发包都是以管程技术为基础的，管程就是一把解决并发问题的万能钥匙

Java 采用的管程技术在哪里体现了呢？synchronized 关键字以及 wait()、notify()、notifyAll() 都是管程的组成部分

管程解决互斥问题的思路：将共享变量以及对共享变量的操作统一封装起来



## synchronized如何保证同步呢？

同步操作主要由两个 jvm 指令实现：`monitorenter、monitorexit`

对于下边代码：

```java
public class LockMain {
    public synchronized void insert() {
        System.out.println("synchronized 方法");
    }
    public void select() {
        synchronized (this) {
            System.out.println("synchronized 块");
        }
    }
}
```

在该类所在的路径，打开命令行执行：

```bash
# 先编译成字节码
javac .\LockMain.java
# 再通过 javap 指令反编译出来 JVM 指令 
# -v 可以输出更多详细信息
javap -v .\LockMain.class
```



反编译后，两个方法的 JVM 指令如下：

```java
public synchronized void insert();
  descriptor: ()V
  flags: ACC_PUBLIC, ACC_SYNCHRONIZED
  Code:
     0: getstatic     #7                  // Field java/lang/System.out:Ljava/io/PrintStream;
     3: ldc           #13                 // String synchronized 方法
     5: invokevirtual #15                 // Method java/io/PrintStream.println:(Ljava/lang/String;)V
     8: return

public void select();
  descriptor: ()V
  flags: ACC_PUBLIC
  Code:
     0: aload_0
     1: dup
     2: astore_1
     3: monitorenter 					  // monitorenter 指令进入同步代码块
     4: getstatic     #7                  // Field java/lang/System.out:Ljava/io/PrintStream;
     7: ldc           #21                 // String synchronized 块
     9: invokevirtual #15                 // Method java/io/PrintStream.println:(Ljava/lang/String;)V
    12: aload_1
    13: monitorexit						  // monitorexit 指令退出同步代码块
    14: goto          22
    17: astore_2
    18: aload_1
    19: monitorexit                       // monitorexit 指令退出同步代码块
    20: aload_2
    21: athrow
    22: return

```

- synchronized 加在方法上，可以看到 insert 方法的 flags 有一个 `ACC_SYNCHRONIZED` 关键字，那么 JVM 进行方法调用时，发现该关键字，就会先获取锁，再执行方法，底层也是基于 monitorenter 和 monitorexit 实现的


- synchronized 加在代码块上，有一个 monitorenter 对应了两个 monitorexit，这是因为编译器会为同步代码块添加一个隐式的 `try-finally`，在 finally 中也会调用 monitorexit 释放锁





## JVM 本地锁：synchronized 锁升级流程

接下来聊一下 JVM 本地锁相关实现原理，通过学习可以了解：

- JDK 内部如何对 synchronized 进行优化提升锁的性能
- 锁的信息在哪里进行存储标记？



### 前言

JDK1.6 之前，synchronized 使用重量级锁，性能开销很高

JDK1.6 引入了锁的优化：`偏向锁和轻量级锁`

同步锁共有 4 个状态：`无锁、偏向锁、轻量级锁、重量级锁`，这 4 个状态会随着竞争激烈而逐渐升级

synchronized 的锁的状态是记录在对象的 Mark Word 中的，因此这里需要先介绍一些 Mark Word

### 对象头 Mark Word

在 64 位 JVM 中，Mark Word 的长度为 64 位

- **Mark Word 到底是 Java 中对象的哪一部分呢？**

在 Java 中，每个对象在堆空间中存储是分为了 3 个部分：对象头、实例数据、对齐填充，对象头中就是存储一些对象的标识信息

而 Mark Word 就是在对象头中进行存储

Mark Word 的作用就是表示对象的线程锁的状态，并且存放对象的 hashCode

<img src="https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240222194643641.png" alt="image-20240222194643641" style="zoom: 80%;" />





我们上边说了 Mark Word 是 64 位的，接下来看一下 Mark Word 如何分配这 64 位的空间

如下图，Mark Word 在以下共 5 种状态下的组成是不一样的，这里来介绍一下：

![image-20240222194117253](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240222194117253.png)

- **无锁时的 Mark Word**

在对象没有锁的时候，我们可以看到 Mark Word 中，前 25bit 没有用到

接下来的 29bit 存储了对象的 HashCode，以及使用 4bit 存储了对象的分代年龄

1bit 存储非偏向锁状态为 0

2bit 存储锁标志位 01，这是固定的

- **有偏向锁的 Mark Word**

当对象 `被偏向锁锁住` 的时候，会使用前 54bit 指向了持有该对象锁的线程，Epoch 代表了偏向锁的版本戳

偏向锁的标志被设置为 1，锁标志位仍然为 01

- **有轻量级锁的 Mark Word**

当对象 `被轻量级锁锁住` 的时候，Mark Word 中的组成又发生了变化

前 62bit 指向了线程栈帧中的 LockRecord

当一个线程持有当前对象锁，并且是轻量级锁的时候，会在线程栈中该线程的栈帧里创建一个 LockRecord 对象（下边在升级轻量级锁的时候会细讲）

你可以先简单理解为这个 LockRecord 就是线程持有该轻量级锁的一个标志

最后 2bit 的锁标志改为 00，表示轻量级锁

- **有重量级锁的 Mark Word**

当对象被 `重量级锁锁住` 的时候，前 62bit 会指向重量级锁，下边升级重量级锁会介绍

最后 2bit 的锁标志改为 10，表示重量级锁

- **有 GC 标志的 Mark Word**

这里了解一下就好了，被 GC 标记过的 Mark Word 就会将锁标志位改为 11

有了 Mark Word 的基础，接下来就可以学习 synchronized 的锁升级过程了！



### 偏向锁

当一个线程第一次竞争到锁，则拿到的就是偏向锁，此时不存在其他线程的竞争，因此偏向锁的性能是很高的，他会偏向第一个访问锁的线程

偏向锁的获取就是通过 CAS 操作将锁对象的 MarkWord 中的 ThreadId 修改为当前线程 ID

当持有偏向锁的线程再来访问的话，可以直接访问，不需要触发同步，连 CAS 操作都不需要

**为什么要引入偏向锁？**

偏向锁是 HotSpot 虚拟机的一项优化技术，可以提升单线程对同步代码块的访问性能

受益于偏向锁的应用程序往往是使用了早期 Java 集合的程序（JDK1.1），即 HashTable、Vector，在每次访问的时候都是 `线程同步操作` 

而之后，出现了新的高性能并发数据结构 ConcurrentHashMap，使用偏向锁带来的性能提升就不明显了

Java 团队更推荐使用 `轻量级锁` 或者 `重量级锁` ：

- 如果竞争不激烈的话，并且每个线程对锁持有时间较短的情况下，可以使用轻量级锁，也就是 CAS 自旋等待获取锁
- 如果竞争激烈的情况下，或者每个线程持有锁的时间很长，如果还是用 CAS 自旋会导致大量线程在空转，大量占用 CPU 资源，因此要使用重量级锁



**为什么在 JDK15 之后就将偏向锁废弃掉了呢？（偏向锁撤销性能差）**

偏向锁在 JDK 15 之后就被废弃掉了，上边已经说了，偏向锁在之后的 JDK 中带来性能提升就不明显了，主要原因其实还是 `偏向锁的撤销` 性能较差

偏向锁只会出现在只有一个线程访问同步代码块时，只要此时有其他线程来访问，偏向锁就会撤销，进而升级为轻量级锁

那么在 `高并发` 场景下，基本上不会出现只有一个线程访问同步代码块的情况

因此会出现 `偏向锁撤销` 的情况，而偏向锁撤销需要等待进入全局安全点（safepoint）时，才会撤销，在 safepoint 时，所有的线程都暂停工作，因此偏向锁撤销的性能很差





### 轻量级锁

如果有线程竞争的话，偏向锁升级为轻量级锁

轻量级锁是通过 `CAS 去自旋` 获取锁，适用于并发竞争不激烈，并且持锁时间较短的情况

当一个线程获取锁之后，其他线程只能自旋等待，不会阻塞，自选等待也就是空转占用 CPU，因此如果自旋时间很长，可以想象到对 CPU 很不友好

**接下来说一下线程竞争轻量级锁的过程**

当进入到 synchronized 代码块中，虚拟机会现在当前线程的栈帧中创建一个 `Lock Record` 的空间，用于存储当前锁对象的 Mark Word 拷贝，官方称这个拷贝的 Mark Word 为 Displaced Mark Word

如果当前线程 `开始抢占` 该锁，那么会先将锁对象的 Mark Word 复制到当前线程栈帧的 Lock Record 中去， **之后再通过 CAS 操作尝试将锁对象的 Lock Record 指针指向当前线程栈帧中的 Lock Record** ，并且将栈帧中的 owner 指针指向对锁对象的 Mark Word

如果通过 CAS 操作更新成功了，就说明该线程抢占到了该锁，将锁对象 Mark Word 的锁标志设置为 00，表示是轻量级锁

如果通过 CAS 操作更新失败，会检查 Mark Word 的 Lock Record 指针是否指向当前线程的栈帧，如果是的话，表明当前线程抢到了锁，可以直接进入，否则会自旋等待

![image-20240222204929963](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240222204929963.png)



**这里说一下为什么需要设计 Lock Record 这个对象再去存储锁对象的 Mark Word**

其实是 `为了存储锁对象的 HashCode` ，对象在无锁状态下 HashCode 会存储在 Mark Word 中

![image-20240222205423283](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240222205423283.png)

但是当锁状态升级为偏向锁之后，原本存储 HashCode 的位置需要存储 `持有锁的线程信息` ，因此这也是偏向锁不能和 HashCode 同时存在的原因

![image-20240222205821147](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240222205821147.png)

因此，为了保存对象的 HashCode 信息，在对象上的锁撤销之后，恢复到 `无锁状态时` ，可以再将对象的 HashCode 信息给写到 Mark Word 上，设计出来了 Lock Record

在给对象加轻量级锁的时候，先将对象的 Mark Word 复制到线程的 Lock Record 中，此时 Lock Record 中保存了对象的 HashCode

在对象上的锁被释放之后，再将 Lock Record 中的 HashCode 赋值给对象的 Mark Word 即可

![image-20240222210115563](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240222210115563.png)





- **这里说一下自适应自旋：**

自旋锁在 JDK 1.4 中就已经引入了，在之前的版本中，自旋次数默认是 10 次（一般认为 10 次自旋大概等于线程挂起的开销）

在 JDK1.6 之后对自旋锁进一步优化，进入了 `自适应自旋`

**自适应自旋：** 自旋的次数不再是一个固定的值了，而是由前一次在该锁上的 `自旋时间` 及 `锁的拥有者的状态` 来决定的

- 如果在当前锁对象上，上次就自旋成功获取锁了，那么当前线程来获取锁时，就会认为自选成功的概率比较大，因此允许自旋相对更长的时间来获取锁
- 如果在当前锁对象上，很少通过自旋获取锁，那么之后在获取锁的时候，可能就直接跳过自旋了





### 重量级锁

当 CAS 自旋达到一定次数，就会升级为重量级锁，避免长时间的 CAS 资源耗费 CPU 性能

在重量级锁中，当线程发现锁已经被占用了，就会将自己挂起，而不是一直占用 CPU 进行空转

而重量级锁的 `性能不高的原因` 就是因为要不断挂起、唤醒线程，进行线程状态的变更， Hostspot 虚拟机采用 `内核线程` 实现线程模型，也就是说 Java 线程都是直接映射到操作系统线程的，因此线程相关的操作都需要在内核态由操作系统执行，导致了用户态切和内核态之间的切换，因此重量级锁性能不高！

- **先说一下 Monitor 的概念：**

每个 Java 对象都与一个 Monitor 相关联，Monitor 的主要目的是确保在任何给定时间，只有一个线程能够执行与特定对象相关联的临界区代码。Monitor 是通过对象头（Object Header）和内置锁（Intrinsic Lock）来实现的，在 JVM 中 Monitor 的具体实现是 ObjectMonitor 

- **接下来说一下，重量级锁的抢占流程（了解一下整体的流程就行，这点的代码都已经是 JVM 层面的了，比较底层）：**

1、当线程准备要抢占重量级锁时，会创建一个 ObjectMonitor （JVM 代码中的 ObjectMonitor）的对象，里边有两个队列 EntryList、WaitSet

![image-20240222220919185](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240222220919185.png)

2、如果该锁正在被其他线程使用，当前线程会先进入到 EntryList 队列中

3、当重量级锁被释放之后，JVM 会指定 EntryList 队列头部的第一个线程为 OnDeck Thread，也就是准备拿到锁的线程

4、如果持有锁的线程被 Object.wait() 方法阻塞，就会转移到 WaitSet 队列，等待被 notify() 或 notifyAll() 唤醒之后进入到 EntryList 队列中

![image-20240222212240919](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240222212240919.png)



这里说一下重量级锁的抢占是 `非公平锁` ，因为线程来抢占重量级锁之前都会先通过 CAS 自选获取锁，如果获取不到了才会进入到队列等待获取重量级锁，因此这对于队列中的线程是不公平的！



当获取了重量级锁之后，就会将锁对象中的 `锁指针` 指向 ObjectMonitor 对象

![image-20240226204046427](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240226204046427.png)





### 总结

最后总结一下

`无锁升级到偏向锁` 比较简单，将对象的 Mark Word 指向当前线程即可

一旦发生多线程竞争锁，就会升级到 `轻量级锁` ，这个抢占过程是通过 CAS 来完成的，主要是通过 CAS 更新锁对象的 Mark Word 值，更新成功说明抢占到了轻量级锁

如果 CAS 达到一定次数，会升级到 `重量级锁` ，这个过程是多个线程在 ObjectMonitor 的阻塞队列中进行排队的



## synchronized 深入剖析

### synchronized 怎么进行锁降级？







### synchronized 可以保证可见性吗？

**首先 synchronized 是可以保证可见性的**

**可见性是什么？**

线程要修改一个变量，这个变量是在主内存中存储的，线程修改时，要先去主内存读取一份到自己的工作内存中，这个工作内存是线程私有的，其他线程看不到，因此如果当前线程修改完毕，没有及时刷新到主内存，或者其他线程读取的时候，没有及时去主内存中读取最新值，就会导致出现数据的不一致问题，也就是数据的不可见，那么保证数据的可见性，就是要保证多个线程中的数据一致性，避免其中一个线程修改变量之后，其他线程看不见变量的更新！

**接下来说一下可见性的保证：**

先从底层说起，可见性的保证，在底层其实是通过 MESI 协议来保证的，也就是保证多个处理器（CPU）和主内存之间的数据一致性，从而保证在操作系统层面上，多个线程之间对数据的更新是可见的

这里说一下 MESI 如何保证数据一致性，只简单说一下，毕竟我们不是专攻底层的

在 MESI 协议中，主要有 `两个关键机制` 来保证数据的一致性：flush 和 refresh

![image-20240226145818519](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240226145818519.png)

- **flush**

将自己更新的值刷新到高速缓存里去，让其他处理器在后续可以通过一些机制从自己的高速缓存里读到更新后的值

并且还会给其他处理器发送一个 flush 消息，让其他处理器将对应的缓存行标记为无效，确保其他处理器不会读到这个变量的过时版本

- **refresh**

处理器中的线程在读取一个变量的值的时候，如果发现其他处理器的线程更新了变量的值，必须从其他处理器的高速缓存（或者是主内存）里，读取这个最新的值，更新到自己的高速缓存中



**上边是硬件级别保证可见性的原理，那么在上层保证可见性其实是基于内存屏障来做的，内存屏障的作用可以理解为强制去读取最新值以及将最新值刷回主内存，也就是有内存屏障的地方会强制线程去执行 refresh 和 flush 动作，从而保证数据的一致性**



**synchronized 保证可见性：**

那么 synchronized 保证可见性其实也就是通过 `内存屏障` 来保证的，在进入 synchronized 代码块和退出的时候，都会插入内存屏障，目的就是保证在进入的时候，强制去执行 refresh 操作，这样可以保证读取到变量的最新值，而在退出 synchronized 代码块时，也就是对变量的修改已经完成了，此使强制去执行 flush 操作，可以保证将变量的最新值给刷新到主内存中去

**如下，在 synchronized 中添加的内存屏障：**

```java
int b = 0;
int c = 0;
synchronized (this) {  --> monitorenter
  --> Load 内存屏障
  --> Acquire 内存屏障
  
  int a = b;
  c = 1;
   
  --> Release 内存屏障
} --> monitorexit
--> Store 内存屏障
```

- `Acquire 屏障 = LoadLoad + LoadStore`
  - Acquire 屏障确保一个线程在执行到屏障之后的内存操作之前，能看到其他线程在屏障之前的所有内存操作的结果
- `Release 屏障 = LoadStore + StoreStore`
  - Release 屏障用于确保一个线程在执行到屏障之后的内存操作之前，其他线程能看到该线程在屏障之前的所有内存操作的结果



这里再介绍一下 JVM 中的内存屏障，也不用都背会，了解内存屏障这个东西就可以了，背会其实没有意义

JMM 中有 4 类`内存屏障`：（Load 操作是从主内存加载数据，Store 操作是将数据刷新到主内存）

- `LoadLoad` ：确保该内存屏障前的 Load 操作先于屏障后的所有 Load 操作。对于屏障前后的 Store 操作并无影响屏障类型 


- `StoreStore` ：确保该内存屏障前的 Store 操作先于屏障后的所有 Store 操作。对于屏障前后的Load操作并无影响
- `LoadStore` ：确保屏障指令之前的所有Load操作，先于屏障之后所有 Store 操作
- `StoreLoad` ：确保屏障之前的所有内存访问操作(包括Store和Load)完成之后，才执行屏障之后的内存访问操作。全能型屏障，会屏蔽屏障前后所有指令的重排

### 为什么不建议在高并发场景下使用 synchronized？

这首先我们要了解 `高并发场景的特点` 以及 `synchronized 底层加锁的原理` 是怎样的！

**首先说一下 synchronized 底层加锁的原理：**

**synchronized 在 JDK1.6 之后引入了锁的优化，随着多线程竞争的激烈程度不同，使用的锁也不同**

- 当没有线程竞争，此时为 `无锁` 状态

- 如果只有一个线程不停访问同步代码块，此时会使用 `偏向锁` 

- 如果有两个以上线程并发访问，偏向锁会撤销，并升级为 `轻量级锁` （偏向锁在 JDK15 之后就被废弃了，因为撤销带来性能开销比较大）

- 如果在轻量锁 CAS 自旋达到一定次数还没有拿到锁，就会撤销轻量级锁，升级为 `重量级锁` ，其实重量级锁的开销是比较大的，因为底层涉及到

在高并发场景下，并发度肯定是比较高的，**不建议使用 synchronized 的原因主要有以下几点：** 

- 由于并发度比较高，因此 synchronized 一定会升级到重量级锁，但是重量级锁的性能是不太高的，因为线程要阻塞再唤醒，需要用户态和内核态之间切换
- synchronized 没有读写锁优化
- synchronized 不能对线程唤醒，也就是你线程如果获取不到锁的话会一直阻塞



在使用 synchronized 的时候，一定要 **直接将偏向锁给禁掉** ，因为大多数情况下，偏向锁都需要撤销升级为轻量级锁，而偏向锁的撤销性能是比较差的！

所以如果优化的话，对于第一个点来说，将等待线程阻塞再唤醒，个人感觉优化空间不大

第二个点就是读写锁的优化，读读之间不互斥，大幅度增强 `读多写少` 场景下的性能！

第三个点就是需要一个 `tryLock(timeout)` 功能，在指定时间获取不到锁的时候，可以直接将线程超时了，不去拿锁了

- **为什么说需要 `tryLock(timeout)` 这个功能呢？**

假设这样一种场景，有一个任务在某个时间点可能多个线程同时要来执行，但是只要有一个线程执行完毕之后，其他线程就不需要执行了

那么假设在这个需要执行任务的时间点，大量线程同时过来执行，也就是大量线程都进入阻塞队列等待获取锁，第一个线程拿到锁执行任务之后，此时后边的线程都不需要执行该任务了，但是由于没有这个超时功能，导致后边的线程还需要在队列中等待获取锁，再一个个进入同步代码块，发现任务已经执行过了，不需要自己再执行了，之后再退出同步代码块

因此这个 `tryLock(timeout)` 的作用就是 **将大量线程的串行操作转为并行操作** ，大量线程发现指定时间内获取不了锁了，直接超时，不获取锁了，这样后边的线程再来看就发现任务已经执行过了，不需要再去获取锁执行任务了

![image-20240226200621006](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240226200621006.png)

这里 `tryLock(timeout)` 的情况只是举一个特殊的情况，其实是参考了分布式环境下，更新 Redis 缓存时会出现这种情况，但是在分布式环境下肯定不会使用 synchronized ，因此这里主要是举个例子说一下 tryLock 的作用！



上边主要说了 synchronized 的缺点，一方面是为了应对面试，另一方面也可以通过各种问题来引发自己的思考，让自己对 synchronized 的理解更加深入

一般在写项目使用分布式锁还是多一些，毕竟高并发项目肯定不会使用单节点部署

而单机项目的话，一般也不会追求极致的性能，使用 synchronized 也没有什么问题



## volatile

synchronized 在多线程场景下存在性能问题

而 `volatile` 关键字是一个更轻量级的线程安全解决方案

volatile 关键字的作用：保证多线程场景下变量的可见性和有序性

- 可见性：保证此变量的修改对所有线程的可见性。
- 有序性：禁止指令重排序优化，编译器和处理器在进行指令优化时，不能把在 volatile 变量操作(读/写)后面的语句放到其前面执行，也不能将volatile变量操作前面的语句放在其后执行。遵循了JMM 的 happens-before 规则

线程写 volatile 变量的过程：

1. 改变线程本地内存中volatile变量副本的值；
2. 将改变后的副本的值从本地内存刷新到主内存

线程读 volatile 变量的过程：

1. 从主内存中读取volatile变量的最新值到线程的本地内存中
2. 从本地内存中读取volatile变量的副本



### volatile 实现原理

如果面试中问到了 volatile 关键字，应该从 Java 内存模型开始讲解，再说到原子性、可见性、有序性是什么

之后说 volatile 解决了`有序性`和`可见性`，但是并不解决`原子性`

volatile 可以说是 Java 虚拟机提供的最轻量级的同步机制，在很多开源框架中，都会大量使用 volatile 保证并发下的有序性和可见性

> volatile 实现 `可见性`和 `有序性` 就是基于 `内存屏障` 的：

内存屏障是一种 `CPU 指令`，用于控制特定条件下的重排序和内存可见性问题

- 写操作时，在写指令后边加上 store 屏障指令，让线程本地内存的变量能立即刷到主内存中
- 读操作时，在读指令前边加上 load 屏障指令，可以及时读取到主内存中的值

JMM 中有 4 类`内存屏障`：（Load 操作是从主内存加载数据，Store 操作是将数据刷新到主内存）

- LoadLoad：确保该内存屏障前的 Load 操作先于屏障后的所有 Load 操作。对于屏障前后的 Store 操作并无影响屏障类型 


- StoreStore：确保该内存屏障前的 Store 操作先于屏障后的所有 Store 操作。对于屏障前后的Load操作并无影响
- LoadStore：确保屏障指令之前的所有Load操作，先于屏障之后所有 Store 操作
- StoreLoad：确保屏障之前的所有内存访问操作(包括Store和Load)完成之后，才执行屏障之后的内存访问操作。全能型屏障，会屏蔽屏障前后所有指令的重排



在字节码层面上，变量添加 volatile 之后，读取和写入该变量都会加入内存屏障：

**读取 volatile 变量时，在后边添加内存屏障，不允许之后的操作重排序到读操作之前**

```java
volatile变量读操作
LoadLoad 
LoadStore
```

**写入 volatile 变量时，前后加入内存屏障，不允许写操作的前后操作重排序**

```java
LoadStore
StoreStore 
volatile变量写操作
StoreLoad
```




**volatile 的缺陷就是不能保证变量的原子性**

解决方案：可以通过加锁或者 `AtomicInteger`原子操作类来保证该变量操作时的原子性

```java
public static AtomicInteger count = new AtomicInteger(0);
```



## CAS

同步组件中大量使用 CAS 技术实现了 Java 多线程的并发操作。整个 AQS 同步组件、Atomic 原子类操作等等都是以 CAS 实现的

Java 中 ConcurrentHashMap 在 jdk1.8 的版本中也调整为了 CAS+Synchronized。可以说 CAS 是整个 JUC 的基石



CAS 操作主要涉及 3 个操作数：

1. V：要写的内存地址
2. E：预期值
3. N：新写入的值

当内存地址的值等于预期值时，将该内存地址的值写为新的值



Java 中的 CAS 通过 `Unsafe` 类实现



**CAS 缺陷：**

1. 循环时间过长：如果 CAS 自旋一直不成功，会给 CPU 带来很大开销

2. 只能针对一个共享变量

3. 存在 ABA 问题：CAS 只检查了值有没有发生改变，如果原本值为 A，被改为 B 之后，又被改为了 A，那么 CAS 是不会发现值被改编过了的

   ABA 问题解决方案：为每个变量绑定版本号，A-->B-->A 加上版本号为：A1-->B2-->A3







## Lock 锁与 AQS

AQS 是抽象队列同步器，是 JUC 中的核心基础组件，AQS 是一个 FIFO 的双向队列，队列中存储的是 thread，JUC 中大部分同步工具类都是基于 AQS 的

线程在获取锁失败之后，会被封装成 Node 节点加入到 AQS 阻塞等待，当获取锁的线程释放锁之后，会从 AQS 队列中唤醒一个线程，AQS 队列如下：

![1702109174153](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/1702109174153.png)



## JUC 中 AQS 结构

JUC 包中提供的锁有：

- ReentrantLock 重入锁
- ReentrantReadWriteLock 读写锁
- StampedLock 读写锁，JDK1.8 引入，是不可重入锁

而 AQS 也就是 AbstractQueuedSynchronizer，是一个同步器，是 JUC 的基础工具类

ReentrantLock 加锁底层就是借助 AQS 来实现的，这里先介绍一下 AQS 的结构以及实现原理



## AbstractQueuedSynchronizer（AQS）

### AQS 介绍

AQS 即抽象队列同步器，基于 AQS 可以用来构建锁和同步器，比如 ReentrantLock、Semaphore、ReentrantReadWriteLock 等等都是基于 AQS 实现的，如下为基于 AQS 实现的同步工具类：

| 同步工具               | 同步工具与AQS的关联                                          |
| :--------------------- | :----------------------------------------------------------- |
| ReentrantLock          | 使用AQS保存锁重复持有的次数。当一个线程获取锁时，ReentrantLock记录当前获得锁的线程标识，用于检测是否重复获取，以及错误线程试图解锁操作时异常情况的处理。 |
| Semaphore              | 使用AQS同步状态来保存信号量的当前计数。tryRelease会增加计数，acquireShared会减少计数。 |
| CountDownLatch         | 使用AQS同步状态来表示计数。计数为0时，所有的Acquire操作（CountDownLatch的await方法）才可以通过。 |
| ReentrantReadWriteLock | 使用AQS同步状态中的16位保存写锁持有的次数，剩下的16位用于保存读锁的持有次数。 |
| ThreadPoolExecutor     | Worker利用AQS同步状态实现对独占线程变量的设置（tryAcquire和tryRelease）。 |

我们也可以基于 AQS 来构建自己需要的同步器，在最后会有一个案例，基于 AQS 实现一把锁



### AQS 数据结构

```java
// AQS 队列头结点
private transient volatile Node head;

// AQS 队列阻塞尾节点
private transient volatile Node tail;

// 当前锁的状态，0：没有被占用，大于 0 代表有线程持有当前锁
// 当 state > 1 时，表锁被重入了，每次重入都加上 1
private volatile int state;

// 代表当前持有独占锁的线程
private transient Thread exclusiveOwnerThread;
```

![image-20240223185212511](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240223185212511.png)







### AQS 的 state 状态

AQS 的 state 状态代表锁是否被占用

- 如果 AQS 的 state 状态为 0 表示当前锁没有被占用

- 如果 AQS 的 state 状态 > 0 表示当前锁被占用

**为什么 > 0 是被占用呢？** 

因为可能会发生锁的重入，每次重入会给 state + 1

**线程通过 CAS 抢占锁**

那么线程来抢占锁，就是通过 CAS 来更新 state 状态，由 0 更改为 1，才算抢锁成功

当没有抢到锁的线程，会被封装为 Node 节点进入 AQS 的队列等待，该节点是由前边一个节点来进行 `唤醒` 的



### AQS 中 Node 的数据结构

AQS 中的 Node 就是对线程的封装，等待锁的线程封装为 Node 进入队列排队，数据结构如下：

```java
// 当前节点的等待状态
volatile int waitStatus;
// 前继指针
volatile Node prev;
// 后继指针
volatile Node next;
// 当前节点中的线程
volatile Thread thread;
// Condition Queue 中的内容，这里不介绍
Node nextWaiter;
```

![image-20240224113855628](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240224113855628.png)



waitStatus 的状态有以下几个，各自的含义不同：

```JAVA
/***********waitStatus 的取值定义***********/
// 表示此线程取消了争抢这个锁请求
static final int CANCELLED =  1;
// 官方的描述是，其表示当前node的后继节点对应的线程需要被唤醒
static final int SIGNAL    = -1;
// 表示节点在等待队列中，节点线程等待唤醒
static final int CONDITION = -2;
// 当前线程处在SHARED情况下，该字段才会使用
static final int PROPAGATE = -3;
```



### AQS 的作用

上边说了 AQS 是 JUC 的基础工具类，ReentrantLock 就是基于 AQS 来写的

那么我们也可以基于 AQS 来实现一个同步工具，如下 Lock 来源为美团技术团队案例代码：

```java
public class LeeLock  {

    private static class Sync extends AbstractQueuedSynchronizer {
        @Override
        protected boolean tryAcquire (int arg) {
            return compareAndSetState(0, 1);
        }

        @Override
        protected boolean tryRelease (int arg) {
            setState(0);
            return true;
        }

        @Override
        protected boolean isHeldExclusively () {
            return getState() == 1;
        }
    }
    private Sync sync = new Sync();
    public void lock () {
        sync.acquire(1);
    }
    public void unlock () {
        sync.release(1);
    }
}
```



同步工具使用：

```java
public class LeeMain {
    static int count = 0;
    static LeeLock leeLock = new LeeLock();
    public static void main (String[] args) throws InterruptedException {
        Runnable runnable = new Runnable() {
            @Override
            public void run () {
                try {
                    leeLock.lock();
                    for (int i = 0; i < 10000; i++) {
                        count++;
                    }
                } catch (Exception e) {
                    e.printStackTrace();
                } finally {
                    leeLock.unlock();
                }

            }
        };
        Thread thread1 = new Thread(runnable);
        Thread thread2 = new Thread(runnable);
        thread1.start();
        thread2.start();
        thread1.join();
        thread2.join();
        System.out.println(count);
    }
}
```





参考资料：

- https://tech.meituan.com/2019/12/05/aqs-theory-and-apply.html
- https://www.cnblogs.com/binarylei/p/12555166.html

## 深入了解 ReentrantLock 底层原理细节

ReentrantLock 底层加锁主要是依靠于 AQS(AbstractQueuedSynchronizer) 来做的，AQS 是 JUC 包下的基础工具类

从名字就可以看出来 AQS 是一个同步器，用于 `管理多线程环境下获取锁` 的问题，接下来会介绍 **ReentrantLock 底层原理** 以及 **AQS 细节！**



### ReentrantLock 构造方法

看 ReentrantLock 的底层原理的话，从它的加锁方法入手：

```java
public class ReentrantLockDemo {
    public static void main(String[] args) {
        ReentrantLock lock = new ReentrantLock();
        lock.lock();
    }
}
```

先来简单看一下 ReentrantLock 的 `构造方法` ：

```java
public ReentrantLock() {
    sync = new NonfairSync();
}
public ReentrantLock(boolean fair) {
    sync = fair ? new FairSync() : new NonfairSync();
}
```

有两个构造方法：

- 默认的无参构造方法的话，将 `sync` 变量声明为了非公平锁
- 有参构造方法传入了 `boolean` 变量，如果是 True，则使用公平锁；如果是 False，则使用非公平锁

**sync 变量是什么？**

sync 变量是 Sync 其实就是在 ReentrantLock 中声明的静态类，继承自 `AbstractQueuedSynchronizer` 也就是 AQS

```java
public class ReentrantLock implements Lock, java.io.Serializable {
	abstract static class Sync extends AbstractQueuedSynchronizer {}
}
```

在 ReentrantLock 的构造方法中创建的 `FairSync` 和 `NonfairSync` 也都是继承自 Sync 类，整体的类结构如下：

```JAVA
public class ReentrantLock implements Lock, java.io.Serializable {
    abstract static class Sync extends AbstractQueuedSynchronizer {}
    static final class NonfairSync extends Sync {}
    static final class FairSync extends Sync {}
}

```

ReentrantLock 的 lock 加锁方法最终就是通过 NonfairSync 和 FairSync 来完成的



### ReentrantLock 非公平锁加锁原理

上边说完了 ReentrantLock 构造方法，接下来看一下加锁的流程是怎样的

先进入到了 ReentrantLock # lock() 方法：

```java
// ReentrantLock
public void lock() {
    sync.lock();
}
```

sync 是什么在上边我们已经说过了，直接跟随源码向下走，这里先说一下 `非公平锁` 的加锁流程（走到了 NonfairSync 类中）：

```java
// ReentrantLock # Sycn # NonfairSync # lock()
final void lock() {
    // CAS 操作抢锁
    if (compareAndSetState(0, 1))
        setExclusiveOwnerThread(Thread.currentThread());
    else
        acquire(1);
}
```

可以看到，在 lock() 方法中，主要有两个 if 分支：

- `compareAndSetState(0, 1)` 成功：这个 CAS 操作用来修改 AQS 队列中的 state 变量，从 0 修改为 1，即 CAS 成功，表示当前线程抢到锁了，直接通过 `setExclusiveOwnerThread` 将当前线程设置到 AQS 中去，此时该线程加锁成功
- `compareAndSetState(0, 1)` 失败：说明加锁失败，直接调用 acquire(1) 操作（之后会讲这个操作）

那么可以看到，如果 CAS 操作抢到锁之后，就可以执行同步代码块中的操作了

那么如果 `CAS 操作没有抢到锁` 的话，会进入到 acquire 方法中，进一步尝试获取锁

- **接下来看一下 acquire() 方法**

上边说了，CAS 失败，也就是当前线程来 CAS 的时候，发现 state 本来的值不是 0，也就是说锁已经被 **某个线程** 持有了，那么就有两种情况了：

1、**当前线程持有 - 锁的重入** ：发现是当前线程持有的锁，因此直接重入，将 state 值加 1 即可

2、**其他线程持有 - 当前线程进入队列等待** ：发现是其他线程持有锁，因此当前线程进入队列等待获取锁

在 acquire 方法中，主要就做上边两件事情，代码如下：

```java
// AbstractQueuedSynchronized
// 方法使用 final 定义，无法重写
public final void acquire(int arg) {
    if (!tryAcquire(arg) &&
        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
        selfInterrupt();
}
```



那么在 acquire 中，有 4 个方法，接下来我们一个一个看这些方法是做什么的：

- **首先看 tryAcquire 方法**

tryAcquire 方法在 FairSync 和 NonFairSync 中都有实现，这里我们先看 NonFairSync 的实现：

```java
// NonFairSync
protected final boolean tryAcquire(int acquires) {
    return nonfairTryAcquire(acquires);
}
final boolean nonfairTryAcquire(int acquires) {
    final Thread current = Thread.currentThread();
    int c = getState();
    if (c == 0) {
        if (compareAndSetState(0, acquires)) {
            setExclusiveOwnerThread(current);
            return true;
        }
    }
    else if (current == getExclusiveOwnerThread()) {
        int nextc = c + acquires;
        if (nextc < 0) // overflow
            throw new Error("Maximum lock count exceeded");
        setState(nextc);
        return true;
    }
    return false;
}
```

可以看到，tryAcquire 最终调用了 `nonfairTryAcquire()` ，来看一下它的执行流程

首先通过 getState() 取出 AQS 队列的 state 状态值

如果 state == 0，说明锁没有被占用，于是通过 CAS 抢锁，抢到之后将持有锁线程设置为自己，是不是很熟悉呢？

在进入 `nonfairTryAcquire()` 之前其实就已经通过 CAS 抢锁失败了，但是这里再抢一次，万一其他线程已经释放了呢？

那么如果 current == getExclusiveOwnerThread() 的话，表明 `当前线程和持有锁的线程是同一个` ，那么直接重入就可以了，重入的次数在 AQS 的 state 值记录，可以看到，将 state + 1 即可

**如果 CAS 没抢到，并且不是重入的话，那就返回 false，这一次的 tryAcquire() 就算失败了，进入接下来的流程**

- **tryAcquire 失败之后，当前线程进入等待队列**

```java
// AbstractQueuedSynchronized
public final void acquire(int arg) {
    if (!tryAcquire(arg) &&
        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
        selfInterrupt();
}
```

为了更方便大家观看，将 acquire 的代码重新贴一下，上边在 tryAcquire 中尝试加锁失败之后，接下来会执行 `acquireQueued(addWaiter(Node.EXCLUSIVE), arg)` 操作，该操作会将当前线程给封装为 Node 节点，之后放入 AQS 的队列中

首先看一下 **addWaiter()** 这个方法：

```java
// AbstractQueuedSynchronized
private Node addWaiter(Node mode) {
    Node node = new Node(Thread.currentThread(), mode);
    Node pred = tail;
    if (pred != null) {
        node.prev = pred;
        if (compareAndSetTail(pred, node)) {
            pred.next = node;
            return node;
        }
    }
    enq(node);
    return node;
}
```

在这个方法中，先将当前 Thread 给包装成了 Node 节点，目的就是向 AQS 中的队列中存放

判断 `if (pred != null)` ，说明 AQS 队列里的已经有节点了，也就是 AQS 队列已经被初始化过了，直接将当前 Node 加入到 AQS 队列去即可，分为了 3 步：

1、声明 pred 变量为 tail，让 node 的前继指针指向 pred

2、通过 CAS 将 AQS 中的 tail 指针指向 node（新加入的 node 节点作为 tail 存在）

3、CAS 成功后，让 pred 的后继指针指向 node

经过这样一通操作，我们刚入队的这个 node 节点就成为了 tail 节点加入到了 AQS 队列中，如下图：

![image-20240223204131694](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240223204131694.png)



如果 `pred == null` ，也就说明 AQS 的队列中，tail 指针没有指向元素， **也就是表明了 AQS 队列此时还没有初始化** ，接下来就通过 `enq(node)` 将 AQS 初始化并把这个 node 插入进去：

```java
// AbstractQueuedSynchronized
private Node enq(final Node node) {
    for (;;) {
        Node t = tail;
        // 没有初始化
        if (t == null) { 
            if (compareAndSetHead(new Node()))
                tail = head;
        } else {
            node.prev = t;
            if (compareAndSetTail(t, node)) {
                t.next = node;
                return t;
            }
        }
    }
}
```

在这个方法中，首先判断 `if (t == null)` 说明 AQS 中的队列都还没有初始化，因此这里初始化一下队列，**初始化操作为** ：创建一个节点，让 AQS 的 head 和 tail 两个指针都指向该节点

![image-20240224144548348](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240224144548348.png)

由于在 for 里是不停循环的，因此在初始化队列之后，就发现 `t != null` 了，因此就可以将 node 节点插入到 AQS 的队列后边去：

![image-20240223205341466](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240223205341466.png)

好，那么到这里，当前线程节点进入 AQS 的等待队列的操作就完成了，我们继续往下看

- **那么当前线程节点已经进入等待队列了，那么看一下接下来还会进行哪些操作？**

```java
// AbstractQueuedSynchronized
public final void acquire(int arg) {
    if (!tryAcquire(arg) &&
        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
        selfInterrupt();
}
```

这里还是为了大家方便看，将 acquire 的代码继续贴出来

上边将 addWaiter() 方法讲完了，node 节点此时已经进入到了 AQS 的等待队列中，那么接下来肯定要将线程给挂起了！

这里我们继续看一下 `acquireQueued()` 方法：

```java
// AbstractQueuedSynchronized
final boolean acquireQueued(final Node node, int arg) {
    boolean failed = true;
    try {
        boolean interrupted = false;
        for (;;) {
            final Node p = node.predecessor();
            if (p == head && tryAcquire(arg)) {
                setHead(node);
                p.next = null; // help GC
                failed = false;
                return interrupted;
            }
            if (shouldParkAfterFailedAcquire(p, node) &&
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
```

在该方法中，先来看 for 循环，先取当前节点的前驱节点，如果前驱节点是头节点的话，那么就说明当前的线程节点已经是 AQS 队列中的第一个节点了，那么他就可以尝试去加锁了，因此这里再通过 tryAcquire 再抢一下锁试试（你可能已经忘了 tryAcquire 是做什么的了，其实就是 CAS 抢锁或者判断是否是重入锁）

如果 tryAcquire 抢到锁了之后，当前节点就没必要在 AQS 的队列中等待获取锁了，因此就将当前 node 节点从队列移除

这里删除当前 node 节点是通过 setHead() 方法删除了，其实就是让 AQS 队列的 Head 指针指向当前 node 节点，让当前的 node 节点作为虚拟头节点，再将原来的虚拟头节点的后继指针设置为空，因此这里注释中的 **`help GC` 其实指的是帮助原来虚拟头节点的 GC 回收** ，如下图：

![image-20240223222911607](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240223222911607.png)

上边说的是当前节点是 AQS 队列中第一个节点的情况，那么如果当前节点不是 AQS 队列中的第一个节点的话，就要走下边的这个逻辑了：

```java
// AbstractQueuedSynchronized
if (shouldParkAfterFailedAcquire(p, node) &&
                parkAndCheckInterrupt())
                interrupted = true;
```

首先要通过 `shouldParkAfterFailedAcquire() ` 方法判断当前 node 节点抢锁失败之后，应不应该被挂起？

**这里为什么要这样判断呢？** 

在队列中，等待获取所需要将当前线程封装为 Node 节点挂起并加入队列，那么当前线程的唤醒需要依赖于上一个线程获取锁之后，在释放锁时，对当前线程进行唤醒

如果上一个线程的状态异常，无法对当前线程唤醒，此时直接把当前线程挂起就可能会存在上一个线程无法唤醒当前线程的情况，代码如下：

```java
// AbstractQueuedSynchronized
private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {
    int ws = pred.waitStatus;
    // 通过上一个线程节点的 waitStatus 来判断是否异常
    if (ws == Node.SIGNAL)
        return true;
        if (ws > 0) {
            do {
                node.prev = pred = pred.prev;
            } while (pred.waitStatus > 0);
            pred.next = node;
        } else {
            compareAndSetWaitStatus(pred, ws, Node.SIGNAL);
        }
    return false;
}
```

判断上一个节点异常就是通过 waitStatus 来判断的，首先拿到当前节点的前继节点的 waitStatus，声明为 ws 变量，waitStatus 的取值都在 Node 类中定义了：

```java
// AbstractQueuedSynchronized # Node
/***********waitStatus 的取值定义***********/
// 表示此线程取消了争抢这个锁请求
static final int CANCELLED =  1;
// 官方的描述是，其表示当前node的后继节点对应的线程需要被唤醒
static final int SIGNAL    = -1;
// 表示节点在等待队列中，节点线程等待唤醒
static final int CONDITION = -2;
// 当前线程处在SHARED情况下，该字段才会使用
static final int PROPAGATE = -3;
```

如果 `ws == Node.SIGNAL` ，说明前继节点可以对当前节点进行唤醒，直接返回 true 就好了（官方对 Node.SIGNAL 的描述是，其表示当前node的后继节点对应的线程需要被唤醒）

如果 `ws > 0` ，那就说明前边的这个线程取消了争抢这个锁的请求，那么前边的节点肯定就无法对当前节点唤醒了，因此把前边状态异常的节点直接跳过就好了，找到一个状态为 `Node.SIGNAL` 的节点即可，如下图：

![image-20240223225351785](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240223225351785.png)

如果 `ws != Node.SIGNAL && ws <= 0` ， 这说明了前边节点的状态不是 Node.SIGNAL，因此要将前边节点的状态设置为 `SIGNAL` ，**表示前边的节点需要对它的后继节点进行唤醒操作！**

```java
// AbstractQueuedSynchronized
if (shouldParkAfterFailedAcquire(p, node) &&
                parkAndCheckInterrupt())
                interrupted = true;
```

这里将代码重复贴一下，上边通过 shouldParkAfterFailedAcquire 判断了当前线程节点是否可以被挂起

如果可以被挂起的话，就调用 `parkAndCheckInterrupt()` 进行挂起：

```java
// AbstractQueuedSynchronized
private final boolean parkAndCheckInterrupt() {
    LockSupport.park(this);
    return Thread.interrupted();
}
```

代码很简单，就是通过 `LockSupport.park()` 对当前线程挂起，**这里注意在线程挂起之后** ，就没有执行接下来的 Thread.interrupted() 方法了，这个方法就是返回线程的中断状态（这里先讲一下每个方法的作用，具体的 `线程唤醒流程` 可以往后看）

```java
// AbstractQueuedSynchronized
public final void acquire(int arg) {
    if (!tryAcquire(arg) &&
        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
        selfInterrupt();
}
```

如上，到此为止在 acquire() 方法中的 if 条件就已经讲完了，这个 if 满足的话，就说明当前线程目前已经被挂起了，之后进入到 `selfInterrupt()` 方法

其实在上边 `parkAndCheckInterrupt()` 方法中，挂起当前线程之后还检测了当前线程的中断状态并返回，但是这个方法会清除掉线程的中断状态：

```java
Thread.interrupted();
```

因此，在 acquire() 的 if 判断都通过之后，需要调用 `selfInterrupt()` 再将中断标志重新设置给当前线程，如下：

```java
static void selfInterrupt() {
    Thread.currentThread().interrupt();
}
```



上边这两个 interrupt 方法的作用不同：

- **interrupt：** 是给线程设置中断标志
- **interrupted：** 是检测中断并清除中断状态



- **加锁流程总结**

到此为止，ReentrantLock 整个加锁的流程就已经说完了，上边的流程还是比较长的，因此这里再简化一下

1、首先，加锁无非就是公平锁和非公平锁，最总走到 FairSync 或者 UnFairSync 中的加锁方法

2、这里以非公平锁为例，首先就是 CAS 抢锁（通过 CAS 设置 AQS 的 state 值）

3、如果当前线程抢到锁，那就将 AQS 的持有锁线程设置为当前线程

4、如果没有抢到锁，就需要将当前线程包装成 Node 节点进入 AQS 队列中排队了

5、不过在排队之前，又尝试了 CAS 抢锁，并且判断了持有锁的线程是否是当前线程，实现了可重入的逻辑

6、如果还没抢到，当前线程的 Node 节点就进入到队列排队了

7、那么由于当前线程进入队列中是需要挂起的，因此需要前边的节点对当前线程节点进行唤醒，因此需要保证当前线程前的节点可以唤醒当前线程，也就是判断前边的节点状态是否为 SIGNAL，将状态异常的节点直接跳过即可

8、那么保证了前边节点可以对当前线程唤醒之后，就可以将当前线程给挂起了，通过 LockSupport.park（接下来的流程，等待线程被唤醒之后，会继续执行）







### ReentrantLock 公平锁和非公平锁加锁的区别

上边说完了非公平锁的主干流程，将主干流程看完之后，其他的一些代码看起来应该难度不大

这里说一下非公平锁和公平锁的区别，其实只在 `tryAcquire` 方法中有不同的地方，这里只将不同的地方列了出来：

```java
/*---------------------公平锁的 tryAcquire()--------------------------*/
protected final boolean tryAcquire(int acquires) {
    final Thread current = Thread.currentThread();
    int c = getState();
    if (c == 0) {
        if (!hasQueuedPredecessors()/*公平锁于非公平锁不同的地方*/ &&
            compareAndSetState(0, acquires)) {
            setExclusiveOwnerThread(current);
            return true;
        }
  // ...
}
/*---------------------非公平锁的 tryAcquire()--------------------------*/
final boolean nonfairTryAcquire(int acquires) {
    final Thread current = Thread.currentThread();
    int c = getState();
    if (c == 0) {
        if (compareAndSetState(0, acquires)) {
            setExclusiveOwnerThread(current);
            return true;
        }
    }
   	// ...
}
```



可以发现，在公平锁的 tryAcquire 方法上，只比非公平锁多了一个 `!hasQueuedPredecessors()` 方法

该方法是判断当前节点在队列中是否还有前继节点，如果有就返回 true；如果没有就返回 false

在公平锁中，要想 `!hasQueuedPredecessors() == true` ，必须 `hasQueuedPredecessors()` 返回 false，也就是当前节点在队列中没有前继节点，那么才可以通过 CAS 去抢锁，**以此来保证公平！**



### Node.CANCELLED 状态节点的产生

上边在讲加锁的流程，其实还有一个地方没有讲到，也就是产生 Node.CANCELLED 节点的操作没有说到，在 `acquireQueued` 方法中，如下：

```java
// AbstractQueuedSynchronized
public final void acquire(int arg) {
    if (!tryAcquire(arg) &&
        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))
        selfInterrupt();
}
// AbstractQueuedSynchronized
final boolean acquireQueued(final Node node, int arg) {
    boolean failed = true;
    try {
        boolean interrupted = false;
        for (;;) {
            final Node p = node.predecessor();
            if (p == head && tryAcquire(arg)) {
                setHead(node);
                p.next = null; // help GC
                failed = false;
                return interrupted;
            }
            if (shouldParkAfterFailedAcquire(p, node) &&
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
```

在 acquireQueued 方法中的 `finally 代码块` ，如果判断当前节点没有成功获取到锁，会调用 `cancelAcquire` 方法标记当前节点状态为 CANCELLED：

```java
private void cancelAcquire(Node node) {
    // 过滤掉无效的节点
    if (node == null)
        return;
    // 将节点上的线程清空
    node.thread = null;

    Node pred = node.prev;
    while (pred.waitStatus > 0)
        node.prev = pred = pred.prev;

    Node predNext = pred.next;

    node.waitStatus = Node.CANCELLED;

    // 分支1：当前节点是 tail 节点
    if (node == tail && compareAndSetTail(node, pred)) {
        compareAndSetNext(pred, predNext, null);
    } else {
        int ws;
        // 分支2：当前节点不是 head 指针的后驱节点，并且((前边节点的状态为 SIGNAL) || (前边节点的状态 <= 0 && 可以成功设置为 SIGNAL))
        if (pred != head &&
            ((ws = pred.waitStatus) == Node.SIGNAL ||
             (ws <= 0 && compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &&
            pred.thread != null) {
            Node next = node.next;
            if (next != null && next.waitStatus <= 0)
                compareAndSetNext(pred, predNext, next);
        } else {
            // 分支3：当前节点是 head 指针的后驱节点或者不满足分支 2 后边的条件
            unparkSuccessor(node);
        }

        node.next = node; // help GC
    }
}
```

接下来我们说一下这个方法中的流程：

首先先拿到当前节点的前驱节点，声明为 `pred` ，拿到后驱节点声明为 `predNext` ，并且将当前节点的 waitStatus 设置为 `Node.CANCELLED`

接下来就是 if 条件判断了，其实是有 3 个分支：

**先来看分支 1** ：如果当前节点是 tail 节点，那么要对当前节点进行取消的话，直接让 tail 指针指向前边的节点就可以了，并且让 `pred` 节点的 next 指针设置为空

![image-20240224212122611](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240224212122611.png)

**再来看分支 2：** 当前节点不是 head 指针的后驱节点，并且((前边节点的状态为 SIGNAL) || (前边节点的状态 <= 0 && 可以成功设置为 SIGNAL))，如果都成立，再判断前边节点的 thread 是否为空，不为空就进入该分支

那么此时通过 CAS 操作将前一个节点的 next 指针指向后一个节点（下图红线）

![image-20240224213118931](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240224213118931.png)

**在哪里修改了 predNext 节点的 prev 指针了呢？**

可以看到上边红线就是修改的地方，虽然将 pred 的 next 指针指向了 predNext，但是并没有将 predNext 指针指向 pred，那么在哪里将 predNext 的 prev 指针指向前边的正常节点呢？

```java
 private static boolean shouldParkAfterFailedAcquire(Node pred, Node node) {
        int ws = pred.waitStatus;
        if (ws == Node.SIGNAL)
            return true;
        if (ws > 0) {
            do {
                // 修改 prev 指针，跳过 CALCELLED 状态的节点，指向正常节点
                node.prev = pred = pred.prev;
            } while (pred.waitStatus > 0);
            pred.next = node;
        } else {
            compareAndSetWaitStatus(pred, ws, Node.SIGNAL);
        }
        return false;
    }
```

这里将 predNext 的 prev 指针修改放在了 shouldParkAfterFailedAcquire 方法中，如果 predNext 这个节点被唤醒，或者发生自旋都会执行 shouldParkAfterFailedAcquire 方法，在这里就会将自己的 prev 指针指向前边的正常节点，也就是 pred 节点，修改完之后，中间的 `待取消节点` 就被孤立起来了，之后会被 GC 掉

![image-20240224214424846](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240224214424846.png)





**最后走到分支 3 ：** 如果当前节点是是 Head 的后驱节点或者是分支 2 后边的条件没有满足（也就是查看当前节点前边的节点中不存在 `未取消状态的节点` ）

那么此时就要去唤醒当前节点的后驱节点了

**这里着重说一下这里为什么要去唤醒当前节点的后驱节点：** 

进入到这里，说明这个没有满足分支 2 的 if 语句，如下：

```java
// 分支 2
if (pred != head &&
            ((ws = pred.waitStatus) == Node.SIGNAL ||
             (ws <= 0 && compareAndSetWaitStatus(pred, ws, Node.SIGNAL))) &&
            pred.thread != null) {
```

1、首先 pred != head 和 pred.thraed == null 这两个条件如果都不满足，他的意思是前边就是头节点，并且当前节点都取消获取锁了，前边也没有线程拿锁，因此直接唤醒后边的线程节点去拿锁就好了

2、`((ws = pred.waitStatus) == Node.SIGNAL || (ws <= 0 && compareAndSetWaitStatus(pred, ws, Node.SIGNAL)))` 

如果这个条件 `不满足` ，说明前驱节点状态不是 SIGNAL，或者通过 CAS 将前驱节点状态设置为 SIGNAL 失败了

**compareAndSetWaitStatus 设置为 SIGNAL 失败** 是因为在高并发情况下，前驱节点突然释放锁了，导致去 CAS 时发现前驱节点状态发生改变，CAS 失败

那么在前驱节点突然释放锁了之后，会对当前节点进行唤醒，结果当前这个节点取消拿锁了，因此当前节点状态也不是 SIGNAL，无法对后边的节点唤醒，**因此这里手动对后边节点唤醒** 





### ReentrantLock 的解锁操作

解锁操作同样也很重要，解锁后会对后边的线程进行唤醒操作

还是从 unlock() 方法调用入手：

```java
public static void main(String[] args) {
    ReentrantLock lock = new ReentrantLock();
    lock.lock();
    lock.unlock();
}
```

直接向下走到核心代码：

```java
// ReentrantLock
public void unlock() {
    sync.release(1);
}

// AbstractQueuedSynchronizer
public final boolean release(int arg) {
    if (tryRelease(arg)) {
        Node h = head;
        if (h != null && h.waitStatus != 0)
            unparkSuccessor(h);
        return true;
    }
    return false;
}
```

可以看到在 release() 方法中，先通过 tryRelease() 尝试释放锁，如果释放成功后，就对后边线程进行唤醒，先来看 `tryRelease` ：

```java
// ReentrantLock
protected final boolean tryRelease(int releases) {
    int c = getState() - releases;
    if (Thread.currentThread() != getExclusiveOwnerThread())
        throw new IllegalMonitorStateException();
    boolean free = false;
    if (c == 0) {
        free = true;
        setExclusiveOwnerThread(null);
    }
    setState(c);
    return free;
}
```

这里的流程就很简单了，releases 变量就是释放锁的个数，为 1，主要是减少重入的次数

令 c = state - release ，如果 c 为 0，表示没有当前线程已经完全不使用这个锁了（所有的重入都已经退出），将持锁线程设置为 null 并且将 AQS 的 state 设置为 0，表示目前锁没有被线程占用

当 tryRelease 返回 true 就表示锁已经释放了，接下来对后边线程进行唤醒即可，执行 `unparkSuccessor` 进行唤醒：

```java
private void unparkSuccessor(Node node) {
    int ws = node.waitStatus;
    if (ws < 0)
        compareAndSetWaitStatus(node, ws, 0);

    Node s = node.next;
    if (s == null || s.waitStatus > 0) {
        s = null;
        for (Node t = tail; t != null && t != node; t = t.prev)
            if (t.waitStatus <= 0)
                s = t;
    }
    if (s != null)
        LockSupport.unpark(s.thread);
}
```

在这个唤醒的方法中，先使用 CAS 将当前节点的 waitStatus 改为 0，表示当前节点已经在对后边节点唤醒了

令 `s = node.next` ：

如果 s 是 null 或者它的 waitStatus > 0，也就是后边的节点是取消状态，因此要通过 for 循环，从后向前找到 node 节点后的第一个正常状态的节点，对这个正常状态节点进行唤醒

如果不满足上边的条件，说明当前节点后边的 s 节点状态正常，直接唤醒 s 节点就可以了

每一个线程节点都是在 `acquireQueued` 方法中挂起的，当被唤醒之后，就会在 acquiredQueued 中的 for 循环中自旋继续执行抢锁操作！

```java
final boolean acquireQueued(final Node node, int arg) {
    boolean failed = true;
    try {
        boolean interrupted = false;
        for (;;) {
            final Node p = node.predecessor();
            if (p == head && tryAcquire(arg)) {
                setHead(node);
                p.next = null; // help GC
                failed = false;
                return interrupted;
            }
            // 线程真正挂起的位置
            if (shouldParkAfterFailedAcquire(p, node) &&
                parkAndCheckInterrupt())
                interrupted = true;
        }
    } finally {
        if (failed)
            cancelAcquire(node);
    }
}
private final boolean parkAndCheckInterrupt() {
    // 挂起
    LockSupport.park(this);
    return Thread.interrupted();
}
```



到此，释放锁以及线程唤醒后在哪里继续开始执行的操作就说完了！

**这里说一下在 unparkSuccessor 中为什么要 `从后向前` 找到 node 后的第一个正常节点呢？**

与 addWaiter() 入队列这个方法有关：

```java
// AbstractQueuedSynchronized
private Node addWaiter(Node mode) {
    Node node = new Node(Thread.currentThread(), mode);
    Node pred = tail;
    if (pred != null) {
        node.prev = pred;
        if (compareAndSetTail(pred, node)) {
            pred.next = node;
            return node;
        }
    }
    enq(node);
    return node;
}
```

可以看到，将线程节点加入队列需要两个操作：`node.prev = pred` 、 `pred.next = node`

但是这两个操作不是原子操作，我们先执行了 `node.prev = pred` ，之后通过 CAS 操作设置 Tail 指针之后，才执行 `pred.next = node`

于是极端情况下可能存在这种情况：当前节点的下一个节点是 CANCELLED 状态，此时新入队的节点只执行了 `node.prev = pred` ，还没来得及执行 `pred.next = node` 

因此，如果 for 循环从前到后遍历的话，可能遍历到 CANCELLED 节点时，此时 next 指针还没有赋值，可能出现空指针的问题

```java
head -> 当前节点 node -> CANCELLED 节点 -> 新入队节点
```

因此可以看到，在 AQS 中大量使用 CAS 无锁操作，虽然性能很高，但是编码复杂度大大上升，很多极端情况如果没有考虑到位，就会出现并发异常。





### ReentrantLock 和 synchronized 区别

**问题：已经有了 synchronized，为什么还需要再基于 AQS 实现 ReentrantLock？**

AQS 是一个底层工具，基于 AQS 可以实现锁 ReentrantLock

在 JVM 层面已经提供了 synchronized 了，为什么还需要在 JDK 层面（Java 语言层面）基于 AQS 去实现 ReentrantLock 锁呢？

synchronized 已经提供了锁功能，在 JDK 又去实现了提供锁功能的 ReentrantLock，相当于是重复造轮子了，接下来分析一下是基于哪个方面的考虑，让 Doug Lea 大师（Java 并发之父）重新造出一套锁工具

- **性能方面**

ReentrantLock 是在 JDK1.5 推出的，synchronized 在 JDK1.6 进行性能优化

优化之后，两种锁的性能差异就不算太大了，如果仅仅因为 synchronized 性能差而造出了 ReentrantLock，那么按理来说，在 JDK1.6 之后，synchronized 的性能已经上来了，大家就没有必要去使用 ReentrantLock 了，但是 ReentrantLock 仍然在使用，那显然不仅仅是因为性能原因

- **使用方面**

synchronized 和 ReentrantLock 在使用方面存在很大的差异性，而就是这些差异性的地方，synchronized 满足不了开发者的需求，因此需要 ReentrantLock 来弥补

synchronized 的使用很简单，直接修饰方法、对象即可，synchronized 存在的问题是：当线程获取不到锁时，会一直阻塞等待，并且阻塞等待的线程也不会释放已经占有的资源

因此 synchronized 的使用是非常不灵活的，它的加锁、解锁操作都是在底层 JVM 层面完成的，很难进行修改



针对不灵活的问题，ReentrantLock 做了这几点改进：

1、可以响应中断：当前线程去获取锁，并阻塞等待，直至获取到锁或者当前线程被中断，即调用 interrupt() 中断当前线程

2、支持超时：当前线程去获取锁，阻塞等待，并且设置最长等待时间，当达到最长等待时间

3、支持非阻塞方式获取锁：如果当前线程已经持有锁，则重入次数 +1；如果锁被其他线程持有，则立即返回失败

![image-20241208154001476](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20241208154001476.png)

ReentrantLock 中相关 API 如下：

```JAVA
// 1、支持中断的API
void lockInterruptibly() throws InterruptedException;
// 2、支持超时的API
boolean tryLock(long time, TimeUnit unit) throws InterruptedException;
// 3、支持非阻塞获取锁的API
boolean tryLock();
```



> 接下来扩展了解一下这三个 API

`lockInterruptibly()` 会让获取锁的线程在阻塞等待的过程中可以响应中断，即当前线程在获取锁的时候，发现锁被其他线程持有，就会阻塞等待

在阻塞等待的过程中，如果其他线程中断当前线程 「`interrupt()`」，就会抛出 `InterruptedException` 异常，可以捕获该异常，做一些处理操作

为了更好理解这个方法，我在 Stack Overflow 上找了一个案例，可以更好地理解 `lockInterruptibly()` 可以响应中断：

```JAVA
public class MyRentrantlock {
    Thread t = new Thread() {
        @Override
        public void run() {
            ReentrantLock r = new ReentrantLock();
            // 1.1、第一次尝试获取锁，可以获取成功
            r.lock();

            // 1.2、此时锁的重入次数为 1
            System.out.println("lock() : lock count :" + r.getHoldCount());

            // 2、中断当前线程，通过 Thread.currentThread().isInterrupted() 可以看到当前线程的中断状态为 true
            interrupt();
            System.out.println("Current thread is intrupted");

            // 3.1、尝试获取锁，可以成功获取
            r.tryLock();
            // 3.2、此时锁的重入次数为 2
            System.out.println("tryLock() on intrupted thread lock count :" + r.getHoldCount());
            try {
                // 4、打印线程的中断状态为 true，那么调用 lockInterruptibly() 方法就会抛出 InterruptedException 异常
                System.out.println("Current Thread isInterrupted:" + Thread.currentThread().isInterrupted());
                r.lockInterruptibly();
                System.out.println("lockInterruptibly() --NOt executable statement" + r.getHoldCount());
            } catch (InterruptedException e) {
                r.lock();
                System.out.println("Error");
            } finally {
                r.unlock();
            }

            // 5、打印锁的重入次数，可以发现 lockInterruptibly() 方法并没有成功获取到锁
            System.out.println("lockInterruptibly() not able to Acqurie lock: lock count :" + r.getHoldCount());

            r.unlock();
            System.out.println("lock count :" + r.getHoldCount());
            r.unlock();
            System.out.println("lock count :" + r.getHoldCount());
        }
    };
    public static void main(String str[]) {
        MyRentrantlock m = new MyRentrantlock();
        m.t.start();
    }
}
```

输出：

```BASH
lock() : lock count :1
Current thread is intrupted
tryLock() on intrupted thread lock count :2
Current Thread isInterrupted:true
Error
lockInterruptibly() not able to Acqurie lock: lock count :2
lock count :1
lock count :0
```



**为什么需要 `tryLock(timeout)` 这个功能呢？**

假设这样一种场景：有一个加载缓存数据的任务在某个时间点多个线程同时要来执行，为了并发安全，通过锁来控制只有一个线程可以执行该任务。

假设大量线程同时来执行该任务，由于需要穿行执行，因此大量线程都进入阻塞队列等待获取锁

当第一个线程拿到锁，执行完任务之后，此时后边的线程都不需要执行该任务了，但是由于没有这个超时功能，导致后边的线程还需要在队列中阻塞等待获取锁，再一个个进入同步代码块，发现任务已经执行过了，不需要自己再执行了，之后再退出释放锁，退出同步代码块。

因此就需要一个支持超时的功能，`tryLock(timeout)` 的作用就是 **将大量线程的串行操作转为并行操作** ，当大量线程等待时间已经超过了指定的超时时间，直接返回 false，表示获取锁失败，不需要大量的线程串行排队等待获取锁。

![image-20241208153800259](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20241208153800259.png)

这里 `tryLock(timeout)` 的情况只是举一个特殊的情况，其实是参考了分布式环境下，更新 Redis 缓存时会出现这种情况，但是在分布式环境下肯定不会使用 synchronized ，因此这里主要是举个例子说一下 tryLock(timeout) 的作用！

## Java线程池的核心内容详解

### 线程池的优势

首先，线程池是将多个线程进行池化操作，统一进行管理，这样做有什么好处呢？

- `降低创建、销毁线程的开销` ：线程池中维护固定数量的线程，不需要临时进行线程的创建和销毁
- `提高响应速度` ：对于新提交到线程池中的任务，直接使用线程池中的空闲线程可以直接进行处理，不需要等待创建线程
- `节省资源`：可以重复利用线程

### 什么场景下要用到线程池呢？

一般就是多 IO 的场景下需要用到，像 IO 任务很多，比如数据库操作、请求其他接口操作，这都属于 IO 类任务，IO 类任务的特点就是只需要线程去启动一下 IO 任务，之后就等待 IO 结果返回即可，**IO 结果返回的时间是比较慢的** ，因此如果只使用单线程去执行 IO 任务的话，由于这个等待时间比较长，那么线程需要一直等待 IO 结果返回，而无法执行其他操作

因此在多 IO 场景下，可以使用线程池来加快 IO 任务的执行，开启多个线程同时去启动多个 IO 任务，可以加快 IO 任务的处理速度



### 线程池中重要的参数【掌握】

线程池中重要的参数如下：

- `corePoolSize` ：核心线程数量
- `maximumPoolSize` ：线程池最大线程数量 = 核心线程数+非核心线程数
- `keepAliveTime` ：非核心线程存活时间
- `unit`：空闲线程存活时间单位（keepAliveTime单位）
- `workQueue` ：工作队列（任务队列），存放等待执行的任务
  - LinkedBlockingQueue：无界的阻塞队列，最大长度为 Integer.MAX_VALUE
  - ArrayBlockingQueue：基于数组的有界阻塞队列，按FIFO排序
  - SynchronousQueue：同步队列，不存储元素，对于提交的任务，如果有空闲线程，则使用空闲线程来处理；否则新建一个线程来处理任务
  - PriorityBlockingQueue：具有优先级的无界阻塞队列，优先级通过参数Comparator实现。
- `threadFactory` ：线程工厂，创建一个新线程时使用的工厂，可以用来设定线程名、是否为daemon线程等等。
- `handler`： 拒绝策略 ，有4种
  - AbortPolicy ：直接抛出异常，默认策略
  - CallerRunsPolicy：用调用者所在的线程来执行任务（主线程执行）
  - DiscardOldestPolicy：丢弃阻塞队列里最老的任务，也就是队列里靠前的任务
  - DiscardPolicy ：当前任务直接丢弃

### 新加入一个任务，线程池如何进行处理呢？【掌握】

新加入一个任务，线程池处理流程如下：

1. 如果核心线程数量未达到，创建核心线程执行
2. 如果当前运行线程数量已经达到核心线程数量，查看任务队列是否已满
3. 如果任务队列未满，将任务放到任务队列
4. 如果任务队列已满，看最大线程数是否达到，如果未达到，就新建非核心线程处理
5. 如果当前运行线程数量未达到最大线程数，则创建非核心线程执行
6. 如果当前运行线程数量达到最大线程数，根据拒绝策略处理

![image-20241028140841042](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20241028140841042.png)

### 如何将任务提交到线程池中呢？

有两种方式：`execute` 和 `submit`

这两种方式的区别：

- execute
  - execute 没有返回值
  - execute 无法捕获任务过程中的异常
- submit
  - submit 会返回一个 `Future` 对象，用来获取任务的执行结果
  - submit 可以通过 Future 对象来捕获任务中的异常

**execute 方式如下：**

```java
ExecutorService executor = Executors.newFixedThreadPool(5);
executor.execute(new Runnable() {
    public void run() {
        // 执行具体的任务逻辑
        System.out.println("Task executed using execute method");
    }
});
executor.shutdown();
```





**submit 方式如下：**

```java
ExecutorService executor = Executors.newFixedThreadPool(5);
Future<String> future = executor.submit(new Callable<String>() {
    public String call() {
        // 执行具体的任务逻辑
        return "Task executed using submit method";
    }
});

try {
    String result = future.get(); // 获取任务执行结果
    System.out.println(result);
} catch (InterruptedException e) {
    // 处理中断异常
} catch (ExecutionException e) {
    // 处理任务执行异常
} finally {
  // 关闭线程池
  executor.shutdown();
}
```





### 线程池是如何关闭的呢？

通过调用线程池的 `shutdown()` 方法即可关闭线程池

调用之后，会设置一个标志位表示当前线程池已经关闭，会禁止向线程池中提交新的任务

去中断所有的空闲线程并且等待正在执行的任务执行完毕（通过调用线程 `interrupt()` 方法），当线程池中所有任务都执行完毕之后，线程池就会被完全关闭



**扩展：thread.interrupt() 方法调用后线程会立即中断吗？**

不会，调用 interrupt 只是将被中断线程的中断状态设置为 true，通知被中断的线程自己处理中断，而不是立即强制的让线程直接中断（强制中断不安全）

当外部调用线程进行中断的命令时，如果该线程处于被阻塞的状态，如 Thread.sleep()，Object.wait()，BlockingQueue#put，BlockingQueue#take 等等时，那么此时调用该线程的 interrupt 方法就会抛出 InterruptedException 异常

因此，可以通过这个特点来优雅的停止线程（在 《Java多线程核心技术》 一书中说到）：将 sleep() 和 interrupt() 搭配使用，来停止线程



### 线程池为什么设计为任务队列满了才创建新线程？

在学习线程池的时候，当任务加入线程池之后，会有一系列处理流程，比较复杂，而面试官也通常喜欢问线程池执行任务的流程。

但是线程池执行任务的流程为什么这样设计，却很少有人提及。这里也从设计者的角度来分析一下，为什么线程池执行任务的流程这样来设计？为什么设计非核心线程数、任务队列等等一系列的参数？

**如果我们作为设计者，会怎样设计一个线程池？**

假如让我们去设计一个线程池，只需要指定线程池中的 **线程数量** 、拒绝策略就可以达到线程池的作用了

**这样会存在什么样的问题？**

假设仅指定线程数量和拒绝策略，在任务加入到线程池之后，直接交给池中的线程来处理，如果没有空闲线程，就直接对任务执行拒绝策略即可。

这样，如果在某一时间出现了突发流量，任务突然提交很多，由于线程数量有限，大量任务会被拒绝，从而导致用户请求大量失败。

可以看到，这样设计出来的线程池，对于突发流量的应对能力是很差的，没有缓存任务的功能，可用性太差。

![image-20241209151413780](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20241209151413780.png)

**那么，线程池执行流程为什么这样设计的原因就很明显了**

这一切都是为了 **高可用** 。

在 Web 服务中，不仅仅需要高性能，还需要高可用，没有高可用一切都是零。一旦服务发生异常，对外不可用，就会造成比较恶劣的影响，尤其是线程池作为底层的组件，一旦出现问题，很多使用线程池的上层应用也都会接连崩溃。

![image-20241209150045604](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20241209150045604.png)

**任务加入到线程池的执行流程：**

任务加入到线程池之后，会先由核心线程来执行，当线程数达到核心线程数之后，会将任务放入到 **任务队列** 中等待执行，当任务队列已经满了之后，才会创建 **非核心线程** 去执行任务。

![image-20241209150053417](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20241209150053417.png)

在这个过程中，任务队列和非核心线程都扮演 **兜底** 的作用，当任务数量超出了核心线程的处理能力之后，就会通过任务队列来存储来不及处理的任务，当任务队列满了之后，还可以创建非核心线程去帮忙处理，以此来提升线程池的可用性。

就比如之前滴滴故障、阿里云故障、语雀故障所带来的影响都是比较大的，所以说高可用设计在开发中一直都是比较重要的内容。



### 线程池中线程异常后，该线程会销毁吗？

向线程池中提交任务有 `execute()` 和 `submit()` ，两种提交方式的区别如下：

- execute 执行任务：execute 没有返回值，无法捕获任务过程中的异常

- submit 执行任务：submit 会返回一个 `Future` 对象，用来获取任务的执行结果，可以通过 Future 对象来捕获任务中的异常



**那么执行过程中发生异常，线程会销毁吗？**

execute 无法捕捉任务过程中的异常是因为当任务在执行时遇到异常的话，如果异常在线程执行过程中没有被捕获的话，该异常就会导致线程停止执行，并且在控制台打印异常，之后该线程会终止，线程池会创建一个新线程来替换他

submit 方式执行任务的话，当执行过程中发生异常，异常会被封装在 `submit()` 返回的 `Future` 对象中，当调用 `Future.get()` 时，可以捕获到 `ExecutionException` 异常，因此使用 `submit()` 发生异常不会终止线程

参考：[线程池中线程异常后：销毁还是复用？](https://mp.weixin.qq.com/s/9ODjdUU-EwQFF5PrnzOGfw)



## 关于线程池在生产环境中的使用

这里整理了一些线程池在生产环境中使用的建议来帮助我们更好的在项目中使用线程池

### 一个项目使用一个线程池还是多个线程池？

一般建议是不同的业务使用不同的线程池，从而避免非核心业务对于核心业务的影响

如果所有的业务使用同一个线程池，非核心业务可能执行速度很慢，从而占用了很多线程迟迟不归还，导致核心业务在任务队列中等待，拿不到线程执行

并且还可能造成 `死锁问题` ，当父子任务使用同一个线程池时，父任务如果将核心线程全部占用之后，等待子任务完成，由于核心线程没有空闲的，导致子任务进入到任务队列中等待线程资源，导致父子任务之间互相等待

### 线程池在 RocketMQ 中的使用

在 MQ 中使用了很多线程池，这里说一下在发送消息时使用的线程池：

1、任务队列：创建了 `异步发送者线程池` ，`任务队列` 使用长度为 50000 的阻塞队列

2、线程数：`核心线程数` 和 `最大线程数` 相同，为 CPU 核数

3、存活时间：`非核心线程存活时间` 60s

4、线程名称：重写了线程工厂，主要是 `为了线程的命名规范` ，这样在查询日志时，只要做好业务之间的隔离，就可以很容易的根据线程名称来定位到对应的业务，便于分析线上问题

```java
private final ExecutorService defaultAsyncSenderExecutor;

private final BlockingQueue<Runnable> asyncSenderThreadPoolQueue;

this.asyncSenderThreadPoolQueue = new LinkedBlockingQueue<Runnable>(50000);

this.defaultAsyncSenderExecutor = new ThreadPoolExecutor(
	Runtime.getRuntime().availableProcessors(),
	Runtime.getRuntime().availableProcessors(),
	1000 * 60,
	TimeUnit.MILLISECONDS,
	this.asyncSenderThreadPoolQueue,
	new ThreadFactory() {
		private AtomicInteger threadIndex = new AtomicInteger(0);

		@Override
		public Thread newThread(Runnable r) {
			return new Thread(r, "AsyncSenderExecutor_" + this.threadIndex.incrementAndGet());
		}
	});
```



那么我们在自己的项目中使用的线程池就可以参考 MQ 中的用法，更加规范的使用线程池

至于为什么要这样设置核心线程数，一方面是参考了设置核心线程数的经验（CPU 密集型的任务令线程数等于 CPU 核心数，减少了线程之间的上下文切换，速度比较快），另一方面 RocketMQ 肯定内部经过性能测试，发现这样设置性能比较好一些





### 关于线程数量的设置

**在项目中，一般使用线程池的场景无非就两种：** 

- `及时性任务` ：需要迅速完成，降低用户等待时间
- `非及时性任务` ：批量完成任务，一般是后台任务

那么对于 `及时性任务` 来说，需要尽可能快的完成任务，因此要 `尽可能增大可执行任务的线程数量` ，来尽可能快的完成任务，`不要设置任务队列` ，因为只有任务队列满了之后，才会去创建非核心线程执行

对于 `非及时性任务` 来说，这类任务并不面向用户，特征是任务量很大，需要批量处理，不需要很低的延迟，因此需要设置合适线程数量， `利用有限的资源去尽可能快的执行任务` ，并且设置任务队列去缓冲任务，但是尽量不要使用无界的任务队列，无界队列任务堆积过多会造成 OOM



- **这里举一个线程池在高并发电商系统中的使用案例**

这里我举一个使用线程池的真实生产环境的案例：**用户消息推送** 

对于中大型电商系统来说，用户量一般最少都达到了千万级，那么如果举办促销活动或者优惠活动了，电商系统肯定需要给用户发送通知，可能会有多个渠道发送比如短信、邮箱等等，那么肯定是需要调用第三方平台的 API 了

调用其他平台 API，毫无疑问就会产生网络 IO，并且是 **千万级别的网络 IO** ，如果只靠单线程去执行，那可能等推送完之后，促销活动也已经结束了

因此，对于这种 IO 任务，并且是大体量推送的 IO 任务，就必须引入线程池来优化性能了，通过多线程来进行任务的推送（当然这里还使用了 RocketMQ 来进行解耦，引入 MQ 之后，就是使用线程池来生成大量消息推送到 MQ 中，消费者再去订阅这些消息去调用第三方平台进行推送，由于该文章主要是讲线程池的，所以这里 MQ 的部分就简单说一下）

```java
ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor(
        0,
        permits * 2,
        60,
        TimeUnit.SECONDS,
        new SynchronousQueue<>(),
        NamedDaemonThreadFactory.getInstance(name)
);
```

这里也将线程池创建的代码给列出来，**这里顺带说一下线程池核心线程的参数为什么设置为 0：** 

因为在消息推送这块，并不是一直要推送的，促销活动、发优惠券，在正常情况下是不会推送发送消息的，因此将核心线程数设置为 0 可以在没有推送任务的时候，将线程池中的线程都回收掉，有任务的时候，再来创建非核心线程执行任务，这样可以避免线程在没有任务时空闲，占用资源

**这里注意任务队列的选用** 

将核心线程数设置为 0 之后，队列使用了 `SynchronousQueue` ，因为这个队列是不存储元素的，因此有任务来了就会创建非核心线程去执行

如果将设置了有容量的任务队列，任务进来之后会先放在队列中，并不会创建非核心线程！





### 美团技术团队针对线程池所做的优化

在美团内部有多次因为线程池参数设置不合理而引发故障的案例

因此可以发现在不同场景下，开发人员对参数的配置有一个大概的方向，**但是具体配置多少还没有一个通用的公式** ，导致上线之后，线程池会因为 `线程数设置过少` 或者 `任务队列设置不合理` 而出现故障

因此美团技术团队设计了 `动态化线程池` ，提供了对 `线程池的监控` 以及参数动态调整，这样在调整参数之后，通过监控可以看到整个线程池的负载情况，可以选出比较合适的参数方案

**那么这里重点的优化提升就在于两点：**

- 线程池参数的动态化设置
- 线程池监控



**这里提一下在线程监控中，对线程池负载的定义**

线程池的负载可以根据活跃的线程数和最大线程数的比值来反映

线程池活跃度 = `activeCount/maximumPoolSize` ，当活跃度升高，代表着线程池负载在逐步上升

还可以 `从任务队列中等待的任务数量` 或者 `发生拒绝策略的次数` 来反映



- **总结一下**

线程池参数的设置没有一个通用的公式，要根据实际场景出发，在设置之后，可以对线程池的性能进行测试，像对线程池进行性能测试的话，就需要对线程池做监控，来看在不同参数下线程池处理任务时的负载表现，来设置更加合理的参数



### 自定义拒绝策略 

在线程池中可以 `自己去定义拒绝策略` ，如果线程池无法处理更多的任务了，可以在自定义的拒绝策略中，将拒绝的任务 `异步持久化` 到磁盘中去，之后再通过一个后台线程去定时扫描这些被拒绝的任务，慢慢执行



**保证严格的任务不丢失：如果线上机器突然宕机，线程池的阻塞队列中的请求怎么办？**

如果宕机，重启之后，线程池阻塞队列中的任务就会全部丢失

如果想要解决这种情况的话，有这么一个 `解决方案` ：在将任务提交到线程池中去的时候，先把任务在数据库中存储一份，并记录任务执行的状态：未提交、已提交、已完成，执行完之后的话，将任务状态标记为 已完成，如果宕机后，导致任务丢失，就可以去数据库中扫描任务，重新提交给线程池执行






### 阿里手册中的线程池规范

在使用线程池的时候，需要注意一些规范，以免出现不必要的问题，可以参考阿里巴巴 Java 开发手册，如下：



**线程池名称命名规范：**

![1707126835124](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/1707126835124.png)



**线程池创建规范：**

![1707126826497](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/1707126826497.png)









## 京东并行框架asyncTool如何针对高并发场景进行优化？

由于最近在整理并发相关的内容，整理了 CompletableFuture、CAS、线程池这些方面的内容，但是通过理论知识我们只是学会了：怎么去用？应该怎么去用？

但是并没有学习别人如何去用，没有实际场景的示范，恰巧看到了 tianyaleixiaowu 作者开源出来的 **asyncTool 并行框架** ，并且已经在 **京东App后台接受苛刻、高并发、海量用户等复杂场景业务的检验测试**

所以这篇文章就以这个并行框架为例，**来说一下如何在高并发场景中保证比较好的性能，即如何通过 CompletableFuture、CAS、线程池去提升性能表现！** 

### asyncTool 介绍及使用

首先介绍一下这个框架的作用，主要是用来进行一些并行任务的编排的，以及任务执行时的一些监控和回调

那么你可能会想了，不是有 CompletableFuture 来做任务编排呢？为什么还需要这个框架？

这个作者也说了，CompletableFuture 虽然提供了任务编排的能力，但是尚有不足，比如我们有多个任务，并对他们编排，但是我们想要 **了解每个任务在开始执行以及执行结束的情况** ，对这些情况进行监控，那么在这种情况下 CompletableFuture 就无能为力了！

这里我们举一个简单的使用例子，有 3 个任务，需要执行完 task1 之后再执行 task2，执行完 task2 之后再执行 task3，流程如下：

![image-20240306193924568](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240306193924568.png)



接下来定义任务，需要实现 `IWorker、ICallback` 两个接口，主要是定义其中的回调以及任务执行方法，这里可以不用具体了解，毕竟我们主要是看它是如何使用线程池的，只需要知道这个 `MyTask1` 是我们需要执行的任务即可

![image-20240306194144787](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240306194144787.png)



接下来我们定义测试类，这里使用了 3 个任务，只需要将上边定义的 `MyTask1` 再复制两份即可

![image-20240306194458355](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240306194458355.png)



在这个测试类中，创建了 3 个任务实例，并且定义了 3 个 `WorkerWrapper` 包装类，这个 `Wrapper` 主要对要执行的任务进行 **包装、编排** ，比如我们定义了 `workerWrapper1` 并通过 `next` 方法指定下一个执行的任务是 `workerWrapper2` ，通过 `next` 进行任务的编排

最后通过 `Async.beginWork()` 来提交任务即可，接下来核心就看 `asyncTool` 是如何执行任务的





### CompletableFuture 和线程池配合使用

上边说如何使用，主要是为了找到任务开始执行的入口，从 **入口** 开始，看框架对于任务的处理：

![image-20240306200130488](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240306200130488.png)



从入口进入，最后走到下边这个 **核心方法** 中：

![image-20240306195936251](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240306195936251.png)



在这个方法中，可以看到是定义了一个 **CompletableFuture 数组** ，来存储任务的异步执行结果

之后将我们定义的任务都扔到 **线程池** 中来执行，来将任务进行异步执行，提升任务执行速度，最后通过通过 `CompletableFuture.allOf().get()` 来阻塞等待所有任务执行完毕，最后返回即可

可以看到，在执行一些耗时操作中，异步化基本上都是必备的操作，也就是通过 **CompletableFuture** 和 **线程池** 来搭配使用，将任务的耗时操作异步化出去，尽量不影响主干流程



### 线程池的定义

上边说到了 asyncTool 中将 **CompletableFuture** 和 **线程池** 搭配使用，线程池具体如何定义的呢，这里其实使用了 `newCachedThreadPool` 线程池，具体的参数定义如下：

![image-20240306201338457](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240306201338457.png)



可以发现该线程池中并没有设置 **核心线程** ，并且 **线程的存活时间设置为 60s** ，任务队列使用了 **SynchronousQueue** 任务队列，**为什么要使用这个线程池呢？**

先从场景来看，这个 asyncTool 框架主要是对提交的并行任务进行编排执行的，**但是该框架其实并不知道任务什么时候会去提交，以及任务的数量大小的** 

所以在 asyncTool 中对于默认线程池的线程数量的设置就没有一个合适的值，如果设置的少了，可能任务提交多了之后， **导致任务堆积 OOM** ；**如果设置的多了，很多线程就会一直空闲，比较浪费线程资源** 

因此呢，就不设置核心线程，将最大线程数设置为 **Integer.MAX_VALUE** ，并且要与任务队列 **SynchronousQueue** 搭配使用

因为线程池的工作流程其实是先来判断有没有核心线程，没有核心线程的话，会将任务提到任务队列中阻塞等待，而 SynchronousQueue 这个任务队列是没有容量的，只做任务传递的作用，因此任务不会阻塞在队列中，直接会创建非核心线程执行任务（如果使用了 **有容量的任务队列** ，就会出现问题了，当任务提交到任务队列之后，此时没有核心线程，任务会一直在任务队列中阻塞，得不到执行）

- **线程池参数这样设置的好处**

当没有任务的时候，线程池中不需要再维护核心线程的存活，可以节约线程资源

当有任务提交的时候，线程池会根据任务的数量来创建对应的线程数量执行任务，这样就不会因为线程数设置过多或者过少而出现一些问题了



### CAS 的使用

asyncTool 框架的目的就是编排并行任务的执行，那么既然是并行任务肯定要保证多线程环境下任务不会重复执行这些情况出现

在 asyncTool 中并没有使用 synchronized 以及 ReentrantLock 这些比较重量级的锁，而是使用 **CAS 来保证任务不会重复执行**

这里看一下在这个框架中，任务真正被执行时的代码，如何来保证任务不被重复执行的（为了重点代码清晰，省略了一部分非核心代码）：

![image-20240306205102997](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20240306205102997.png)



可以看到，在真正执行任务之前，会先通过 **CAS** 来判断任务的状态是否是 **INIT** ，是的话，表示任务还没有被执行；如果不是的话，说明已经被执行过了，或者任务出现了异常，这里直接返回结果就好了

如果 **CAS** 操作失败，说明任务的状态并不是 **INIT** ，任务已经开始执行了，所以这里就不要重复执行了

并且在执行完任务之后，再次通过 **CAS** 操作判断任务状态，如果已经不是 **WORKING** ，说明其他线程已经执行完该任务了或者其他线程在执行时发现任务出现异常，因此这里就直接返回了，避免在后边重复的进行任务回调操作



#### 为什么说 CAS 操作比较轻量呢？

这个如果了解 synchronized 的锁升级流程的话，应该就知道为什么

在 synchronized 锁升级的过程中，轻量级锁就是通过 **CAS** 来获取锁的，而重量级锁是通过 **线程的阻塞、唤醒** 进行线程之间的获取锁操作

那么 **CAS** 操作性能就高在了它只需要去内存中进行值的比对，发现内存的值和期望值不同，就直接返回操作失败就可以了

**如果在 asyncTool 中使用 synchronized 来保证线程之间的同步的话，这还需要进行线程之间的阻塞、唤醒操作，因此会出现线程之间的上下文切换以及用户态和内核态之间的转换，导致性能开销比较大**

所以在 asyncTool 不去对线程同步进行控制，而是通过 **CAS** 来避免一些因为重复操作可能会带来的问题，这样性能就比较高了



**asyncTool 开源框架项目地址：** https://gitee.com/jd-platform-opensource/asyncTool

如果需要测试代码的话，可以从我 fork 的仓库中拉取：https://gitee.com/qylaile/asyncTool



## CompletableFuture 原理与实践

### 1、CompletableFuture 使用



**为什么要使用 CompletableFuture?**

一个接口可能需要调用 N 个其他服务的接口，这在项目开发中还是挺常见的。举个例子：用户请求获取订单信息，可能需要调用用户信息、商品详情、物流信息、商品推荐等接口，最后再汇总数据统一返回。

如果是串行（按顺序依次执行每个任务）执行的话，接口的响应速度会非常慢。考虑到这些接口之间有大部分都是 **无前后顺序关联** 的，可以 **并行执行** ，就比如说调用获取商品详情的时候，可以同时调用获取物流信息。通过并行执行多个任务的方式，接口的响应速度会得到大幅优化.





**为什么不使用Future?**

`Future` 对结果的获取不是很友好，只能通过阻塞或轮询的方式得到任务的结果，功能相比于 CompletableFuture 较少

因此，Java 8 才被引入的 `CompletableFuture` 可以帮助我们来做多个任务的编排，功能非常强大。



以下简称 CompletableFuture 为 CF

#### CompletableFuture 的创建

CompletableFuture 的创建有两种方式：

1、通过 new 关键字

2、基于静态工厂方法：：`runAsync()`、`supplyAsync()` 。



**方式 1、使用 new 关键字创建**

`CompletableFuture<String> cf = new CompletableFuture<>();`

如果已经知道结果，可以直接将结果复制给 CF

`CompletableFuture<String> future = CompletableFuture.completedFuture("result value");`



**方式 2、使用静态工厂方法创建**

这里在创建任务的时候，推荐使用自定义的线程池，可以让我们清楚的知道任务运行在哪个线程之上，并且可以根据实际情况做线程池的隔离。

静态工厂方法有两个：`runAsync()：无返回值`、`supplyAsync()：有返回值`

```java
public void staticFactoryMethod() throws ExecutionException, InterruptedException {
    CompletableFuture<Void> cf1 = CompletableFuture.runAsync(() -> {
        System.out.println("runAsync创建，无返回值");
    });
    CompletableFuture<String> cf2 = CompletableFuture.supplyAsync(() -> {
        System.out.println("supplyAsync创建，有返回值");
        return "result";
    });
    System.out.println(cf1.get());
    System.out.println(cf2.get());
    /**
     * 输出结果：
     * runAsync创建，无返回值
     * supplyAsync创建，有返回值
     * null
     * result
     */
}
```



#### CompletableFuture 处理计算结果

当我们获取到异步计算的结果之后，还可以对其进行进一步的处理，比较常用的方法有下面几个：

- `thenApply()` ：会沿用上一个任务的线程池
- `thenAccept()` 
- `thenRun()`
- `whenComplete()`



```java
// 沿用上一个任务的线程池
public <U> CompletableFuture<U> thenApply(
    Function<? super T,? extends U> fn) {
    return uniApplyStage(null, fn);
}

//使用默认的 ForkJoinPool 线程池（不推荐）
public <U> CompletableFuture<U> thenApplyAsync(
    Function<? super T,? extends U> fn) {
    return uniApplyStage(defaultExecutor(), fn);
}
// 使用自定义线程池(推荐)
public <U> CompletableFuture<U> thenApplyAsync(
    Function<? super T,? extends U> fn, Executor executor) {
    return uniApplyStage(screenExecutor(executor), fn);
}
```



- `thenApply()`

```java
public void thenApply() throws ExecutionException, InterruptedException {
    CompletableFuture<String> cf1 = CompletableFuture.supplyAsync(() -> {
        System.out.println("supplyAsync创建，有返回值");
        return "result";
    });
    CompletableFuture<String> cf2 = cf1.thenApply(res -> res + "调用thenApply");
    System.out.println(cf2.get());
    /**
     * 调用结果：
     * result调用thenApply
     */
}
```



- `thenAccept()`和`thenRun()`：`thenAccept` 接收 Consumer 接口，`thenRun` 接收线程

```java
CompletableFuture.completedFuture("hello!")
        .thenApply(s -> s + "world!").thenApply(s -> s + "nice!").thenAccept(System.out::println);//hello!world!nice!

CompletableFuture.completedFuture("hello!")
        .thenApply(s -> s + "world!").thenApply(s -> s + "nice!").thenRun(() -> System.out.println("hello!"));//hello!
```



- `whenComplete()`：接收2个输入对象进行消费

```java
CompletableFuture<String> future = CompletableFuture.supplyAsync(() -> "hello!")
        .whenComplete((res, ex) -> {
            // res 代表返回的结果
            // ex 的类型为 Throwable ，代表抛出的异常
            System.out.println(res);
            // 这里没有抛出异常所有为 null
            assertNull(ex);
        });
assertEquals("hello!", future.get());

```



#### 异常处理

- 使用 `handle` 处理异常

```java
public void handleExe() throws Exception {
    CompletableFuture<String> cf1 = CompletableFuture.supplyAsync(() -> {
        if (true) {
            throw new RuntimeException("抛出异常！");
        }
        return "result";
    }).handle((res, ex) -> {
        System.out.println("res:" + res);
        System.out.println("ex:" + ex);
        return res;
    });
    System.out.println(cf1.get());
    /**
     * 输出结果：
     * res:null
     * ex:java.util.concurrent.CompletionException: java.lang.RuntimeException: 抛出异常！
     * null
     */
}
```



- 使用 `exceptionally` 处理异常

由于异步执行的任务在其他线程上执行，而异常信息存储在线程栈中，因此当前线程除非阻塞等待返回结果，否则无法通过try\catch捕获异常。CompletableFuture提供了异常捕获回调exceptionally，相当于同步调用中的try\catch。使用方法如下所示：

```java
@Autowired
private WmOrderAdditionInfoThriftService wmOrderAdditionInfoThriftService;//内部接口
public CompletableFuture<Integer> getCancelTypeAsync(long orderId) {
    CompletableFuture<WmOrderOpRemarkResult> remarkResultFuture = wmOrderAdditionInfoThriftService.findOrderCancelledRemarkByOrderIdAsync(orderId);//业务方法，内部会发起异步rpc调用
    return remarkResultFuture
      .exceptionally(err -> {//通过exceptionally 捕获异常，打印日志并返回默认值
         log.error("WmOrderRemarkService.getCancelTypeAsync Exception orderId={}", orderId, err);
         return 0;
      });
}

```

有一点需要注意，CompletableFuture在回调方法中对异常进行了包装。大部分异常会封装成CompletionException后抛出，真正的异常存储在cause属性中，因此如果调用链中经过了回调方法处理那么就需要用Throwable.getCause()方法提取真正的异常。但是，有些情况下会直接返回真正的异常（[Stack Overflow的讨论](https://stackoverflow.com/questions/49230980/does-completionstage-always-wrap-exceptions-in-completionexception)），最好使用工具类提取异常，如下代码所示：

```java
@Autowired
private WmOrderAdditionInfoThriftService wmOrderAdditionInfoThriftService;//内部接口
public CompletableFuture<Integer> getCancelTypeAsync(long orderId) {
    CompletableFuture<WmOrderOpRemarkResult> remarkResultFuture = wmOrderAdditionInfoThriftService.findOrderCancelledRemarkByOrderIdAsync(orderId);//业务方法，内部会发起异步rpc调用
    return remarkResultFuture
          .thenApply(result -> {//这里增加了一个回调方法thenApply，如果发生异常thenApply内部会通过new CompletionException(throwable) 对异常进行包装
      //这里是一些业务操作
        })
      .exceptionally(err -> {//通过exceptionally 捕获异常，这里的err已经被thenApply包装过，因此需要通过Throwable.getCause()提取异常
         log.error("WmOrderRemarkService.getCancelTypeAsync Exception orderId={}", orderId, ExceptionUtils.extractRealException(err));
         return 0;
      });
}

```

上面代码中用到了一个自定义的工具类ExceptionUtils，用于CompletableFuture的异常提取，在使用CompletableFuture做异步编程时，可以直接使用该工具类处理异常。实现代码如下：

```java
public class ExceptionUtils {
    public static Throwable extractRealException(Throwable throwable) {
          //这里判断异常类型是否为CompletionException、ExecutionException，如果是则进行提取，否则直接返回。
        if (throwable instanceof CompletionException || throwable instanceof ExecutionException) {
            if (throwable.getCause() != null) {
                return throwable.getCause();
            }
        }
        return throwable;
    }
}
```



#### 编排任务

- `thenCompose()` 按顺序链接两个 `CompletableFuture` 对象，实现异步的任务链。它的作用是将前一个任务的返回结果作为下一个任务的输入参数，从而形成一个依赖关系。
- `thenCombine()` 会在两个任务都执行完成后，把两个任务的结果合并。两个任务是并行执行的，它们之间并没有先后依赖顺序。
- 如果我们想要实现 task1 和 task2 中的任意一个任务执行完后就执行 task3 的话，可以使用 `acceptEither()`。

```java
public void thenCompose() throws ExecutionException, InterruptedException {
    CompletableFuture<String> cf1 = CompletableFuture.supplyAsync(() -> "hello!")
        .thenCompose(res -> CompletableFuture.supplyAsync(() -> res + "world!"));
    System.out.println(cf1.get());
    /**
     * 输出结果：
     * hello!world!
     */
}

public void thenCombine() throws ExecutionException, InterruptedException {
    CompletableFuture<String> cf1 = CompletableFuture.supplyAsync(() -> "hello!")
                    .thenCombine(CompletableFuture.supplyAsync(()-> "world"), (res1, res2) -> res1 + res2);
    System.out.println(cf1.get());
    /**
     * 输出结果：
     * hello!world
     */
}
```



#### 并行运行多个任务

- `allOf` 可以并行运行多个任务，等到所有任务运行完再返回
- `anyOf` 任意一个任务执行完之后，即可返回

```java
public void paraTask() throws ExecutionException, InterruptedException {
    CompletableFuture<String> cf1 = CompletableFuture.supplyAsync(() -> "task1");
    CompletableFuture<String> cf2 = CompletableFuture.supplyAsync(() -> "task2");
    CompletableFuture<String> cf3 = CompletableFuture.supplyAsync(() -> "task3");
    CompletableFuture<String> cf4 = CompletableFuture.supplyAsync(() -> "task4");
    CompletableFuture<String> cf5 = CompletableFuture.supplyAsync(() -> "task5");
    CompletableFuture<String> cf6 = CompletableFuture.supplyAsync(() -> "task6");
    CompletableFuture<Void> headerFuture = CompletableFuture.allOf(cf1, cf2, cf3, cf4, cf5,cf6);
    headerFuture.join();

    System.out.println(headerFuture.get());
    System.out.println("完成");
}
```



### 2、CompletableFuture使用中常见问题



#### 2.1 使用自定义线程池

如果在使用中，没有传入自定义线程池，将使用默认线程池 ForkJoinPool 中的共用线程池 CommonPool（CommonPool的大小是CPU核数-1，如果是IO密集的应用，线程数可能成为瓶颈）

如果执行两个任务时，传入了自定义的线程池，使用 thenRun 和 thenRunAsync 还有一点小区别;

- 当使用 `thenRun` 执行第二个任务时，将会使用和第一个任务相同的线程池
- 当使用 `thenRunAsync` 执行第二个任务时，那么第一个任务会使用自己传入的线程池，而第二个任务则会使用 `ForkJoin` 线程池。（`thenAccept、thenApply`同理）

在实际使用时，建议使用自定义的线程池，并且根据实际情况进行线程池隔离。避免核心业务与非核心业务竞争同一个池中的线程，减少不同业务之间相互干扰



#### 2.2 线程池循环引用导致死锁

```java
public Object doGet() {
  ExecutorService threadPool1 = new ThreadPoolExecutor(10, 10, 0L, TimeUnit.MILLISECONDS, new ArrayBlockingQueue<>(100));
  CompletableFuture cf1 = CompletableFuture.supplyAsync(() -> {
  //do sth
    return CompletableFuture.supplyAsync(() -> {
        System.out.println("child");
        return "child";
      }, threadPool1).join();//子任务
    }, threadPool1);
  return cf1.join();
}
```

对于上边代码，如果同一时刻有 10 个请求到达，`threadPool1` 被打满，而 `cf1` 的 子任务也需要使用到 `threadPool1` 的线程，从而导致子任务无法执行，而且父任务依赖于子任务，也无法结束，导致死锁。



参考文章：

Java Guide：https://javaguide.cn/java/concurrent/completablefuture-intro.html#%E4%BD%BF%E7%94%A8%E8%87%AA%E5%AE%9A%E4%B9%89%E7%BA%BF%E7%A8%8B%E6%B1%A0

美团技术团队：https://tech.meituan.com/2022/05/12/principles-and-practices-of-completablefuture.html





## 什么是伪共享？伪共享问题如何解决？开源高性能无锁内存队列 Disruptor 如何解决？

### 背景

当我们想实现一个生产者-消费者模型时，为了保证并发场景下的数据安全，在生产者和消费者之间需要一个共享缓冲区，通过控制共享缓冲区的访问来保证并发安全，常见的比如说使用 JDK 自带的 ArrayBlockingQueue，内部通过 ReentrantLock 和 Condition 来保证并发安全，但是他存在一个问题就是 **性能比较差！**

针对性能差可以采用无锁方案 CAS 来保证并发安全，比如 **ConcurrentLinkedQueue** 就是通过 CAS 来保证了线程安全，但是无锁方案具体的实现 **比较复杂** ，如果我们想在自己业务中使用 CAS 实现一个生产者-消费者模型的话， **实现成本相当高**

Disruptor 就是一个高性能的、无锁的内存队列，通过无锁化的方式来保证较好的性能，其核心是一个 **环形队列** ，这个队列能够在无锁的条件下进行并行消费，因此我们如果需要一个高性能的队列去作为一个缓冲区存储数据，那就使用 Disruptor 没错了！



**接下来介绍一下 Disruptor 框架中常见概念**

### RingBuffer

基于数组实现的一个环，用于在不同线程间传递数据，RingBuffer 有一个 Sequencer 序号器，指向数组中下一个可用元素

![1702028274751](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/1702028274751.png)





### WaitStrategy 等待策略

消费者等待生产者将数据放入 RingBuffer，有不同的等待策略：

- `BlockingWaitStrategy`：阻塞等待策略（默认策略），最低效的策略，通过锁和 Condition 来实现线程的阻塞和唤醒，因此对 CPU 的消耗最小并且在各种不同部署环境中能提供更加一致的性能表现。
- `SleepingWaitStrategy`：休眠等待策略，性能表现跟 BlockingWaitStrategy 差不多，先自旋等待，如果不成功再通过 `Thread.yield()` 让出 CPU，因此 对 CPU 的消耗也和默认策略类似，好处是其对生产者线程的影响最小，适合用于异步日志等对延时要求不高的场景
- `YieldingWaitStrategy`：产生等待策略，适合用于低延迟的系统，会死循环不断执行 `Thread.yield()` 让出 CPU 给其他线程使用，在要求极高性能且事件处理线程数小于 CPU 逻辑核心数的场景中，推荐使用。是无锁并行
- `BusySpinWaitStrategy`：忙碌自旋等待策略，延时最低，会死循环不断去查看缓冲区内的数据变化，因此会一直占用 CPU，消耗大量的 CPU 资源，事件处理线程数量必须小于 CPU 物理核心数



Disruptor 的设计中是没有锁的，在 Disruptor 中出现线程竞争的地方也就是 RingBuffer 中的下标 Sequence，Disruptor 通过 CAS 操作来代替加锁，从而提升性能，CAS 的性能大约是加锁操作性能的 8 倍，



### 伪共享问题

在并发场景中，伪共享问题会导致多线程访问数据性能很差，因此 Disruptor 中还针对`伪共享问题` 给出了解决方案，接下来看一下他是如何解决的

#### 什么是伪共享？

**缓存行的概念**

为了提升 CPU 速度，CPU 会有一个高速缓存（Cache），该缓存由很多个 cache line 组成，每个 cache line 通常是 64B，并且可以有效地引用主内存中的一块地址。

Java 中 long 类型变量是 8B，因此一个 cache line 可以存储 8 个 long 类型变量

CPU 每次从主存中拉取数据时，会把相邻的数据也存入同一个 cache line，如果多个变量在主内存中是相邻的，那么多个变量可能会被加载到同一个 cache line 中



**伪共享问题**

在 Disruptor 框架中，Sequence 组件会被频繁访问，主要使用的就是 Sequence 内部的 value 值，因此 Disruptor 对这个 value 值解决了伪共享问题，避免该 value 值和其他数据存储在同一个缓存行，导致缓存频繁失效

如果 value 值和其他变量处于同一个 cache line 中的话，假如此时有两个线程对该缓存行的数据进行操作，比如线程 A 修改了该缓存行里的数据变量，那么就会导致这一个缓存行（cache line）失效，此时线程 B 去访问该 value 值会无法命中缓存，需要从内存重新读取

这种多个变量共享同一个缓存行，从而导致频繁无法命中 CPU 缓存的现象，称为 `伪共享`

**解决方案** 就是在对应变量的前后增加一些占位空间，使得该变量独占一个 cache line，从而使得不同线程存取的元素位于不同的 cache line 上，通过空间换时间（比如 cache line 通常为 64B，想要解决 long 型数据的伪共享问题，可以在该 long 型数据前添加 7 个 long 型数据）

> 在jdk1.8中，有专门的注解 `@Contended` 来避免伪共享，更优雅地解决问题。

#### Disruptor 解决伪共享

内部代码如下，Sequence 继承自 RhsPadding，在 value 的前后都增加了 7 个字节的填充，来让该 value 值独占一个缓存行

```JAVA
class LhsPadding
{
    protected long p1, p2, p3, p4, p5, p6, p7;
}

class Value extends LhsPadding
{
    protected volatile long value;
}

class RhsPadding extends Value
{
    protected long p9, p10, p11, p12, p13, p14, p15;
}
public class Sequence extends RhsPadding {...}
```





### 解决伪共享性能提升代码实践

接下来给出代码，来验证解决伪共享问题之后是可以提升性能的

**场景：** 设置多个线程去同时去更新数组中的数据，最后打印耗时

**性能分析：** 

- **未解决伪共享问题：** 如果未解决伪共享问题，那么其中一个线程更新数据之后，就会导致该数据所在缓存行（cache line）的数据失效，因此其他线程需要去主内存中读取对应数据， **会花费更多的时间**
- **已解决伪共享问题：** 通过对数据进行填充，让每个数据占用一个缓存行（cache line），那么线程更新一个缓存行的数据，不会导致其他线程访问的数据在 CPU 缓存中失效， **因此该方式会花费较少的时间**



**解决伪共享代码如下：** 这里在示例中，所有的数据都在数组中，是连续存放的，所以只需要填充 6 字节，就可以让一个 value 占有一个缓存行了；而在 Disruptor 中，value 只是单独存放，如果只在前边填充 7 个字节，那么可能有部分填充处于上一个缓存行，因此在前边和后边都添加 7 个字节，来保证 value 可以百分百可以占有一个缓存行

```JAVA
private static class PaddedCounter {
    public volatile long value = 0L;
    // 填充 48 字节（6 个 long，每个 8 字节），再加上对象头 8 字节，避免不同 Counter 实例共享缓存行
    public long p1, p2, p3, p4, p5, p6;
}
```

![image-20241022130303785](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/image-20241022130303785.png)





**代码如下：**

```JAVA
public class PaddedFalseSharingTest {

    // 解决伪共享问题的 Counter，使用缓存行填充
    private static class PaddedCounter {
        public volatile long value = 0L;
        // 填充 48 字节（6 个 long，每个 8 字节），再加上对象头 8 字节，避免不同 Counter 实例共享缓存行
        public long p1, p2, p3, p4, p5, p6,;
    }

    private static final int NUM_THREADS = 4;
    private static final long ITERATIONS = 100_000_000L;
    private static final PaddedCounter[] counters = new PaddedCounter[NUM_THREADS];
    static {
        for (int i = 0; i < NUM_THREADS; i++) {
            counters[i] = new PaddedCounter();
        }
    }

    public static void main(String[] args) throws InterruptedException {
        long startTime = System.nanoTime();
        runTest();
        long endTime = System.nanoTime();
        System.out.println("总计花费时间: " +
                TimeUnit.NANOSECONDS.toMillis(endTime - startTime) + " ms");
    }

    private static void runTest() throws InterruptedException {
        Thread[] threads = new Thread[NUM_THREADS];

        for (int i = 0; i < NUM_THREADS; i++) {
            final int index = i;
            threads[i] = new Thread(() -> {
                for (long j = 0; j < ITERATIONS; j++) {
                    counters[index].value = j;
                }
            });
        }
        for (Thread thread : threads) {
            thread.start();
        }
        for (Thread thread : threads) {
            thread.join();
        }
    }
}
```





**时间对比：**

- 未解决伪共享问题：（需要注释 **PaddedCounter** 类中的 p1、p2、...、p7 变量的定义）总计花费时间: 4419 ms
- 已解决伪共享问题：总计花费时间: 600 ms

**总结：** 解决伪共享问题之后，各个线程修改各自的数据，不会导致各个线程访问的数据在 CPU 缓存内频繁失效，从而提升性能



**Disruptor 通过哪些设计来解决队列速度慢的问题了呢？**

- 环形数组 RingBuffer

  采用环形数组，空间重复利用，避免垃圾回收，并且数组对于缓存机制更加友好

- 元素位置定位

  数组长度 2^n，通过位运算，加快定位速度

- 无锁设计

  通过 CAS 代替锁来保证操作的线程安全

  在美团内部，很多高并发场景借鉴了Disruptor的设计，减少竞争的强度。其设计思想可以扩展到分布式场景，通过无锁设计，来提升服务性能

- 解决伪共享问题：加快多线程操作数据的性能（空间换时间）



**Disruptor 多个生产者、多个消费者原理**

在 Disruptor 中，多个生产者生产数据时，每个线程获取不同的一段数组空间再加上 CAS 操作，可以避免多个线程重复写同一个元素

在读取时，如何避免读取到未写的元素呢？

Disruptor 中新创建了一个与 RingBuffer 大小相同的 available Buffer，当某个位置写入成功，就在 available Buffer 中标记为 true，通过该标记来读取已经写好的元素



### Disruptor 单生产者单消费者实战

首先引入依赖：

```xml
<dependency>
    <groupId>com.lmax</groupId>
    <artifactId>disruptor</artifactId>
    <version>3.3.4</version>
</dependency>
```



定义订单：

```java
/**
 * 订单对象，生产者要生产订单对象，消费者消费订单对象
 */
public class OrderEvent {
    // 订单的价格
    private long value;

    public long getValue() {
        return value;
    }

    public void setValue(long value) {
        this.value = value;
    }
}
```



定义工厂类，用于创建订单对象：

```java
/**
 * 建立一个工厂类，用于创建Event的实例（OrderEvent)
 */
public class OrderEventFactory implements EventFactory<OrderEvent> {
    @Override
    public OrderEvent newInstance() {
        // 生产对象
        return new OrderEvent();
    }
}
```



定义事件处理器，用于监听消费订单：

```java
/**
 * 消费者
 */
public class OrderEventHandler implements EventHandler<OrderEvent> {
    @Override
    public void onEvent(OrderEvent orderEvent, long l, boolean b) {
        System.err.println("消费者:" + orderEvent.getValue());
    }
}
```



定义生产者，用于生产订单：

```java
public class OrderEventProducer {

    // ringBuffer 用于存储数据
    private RingBuffer<OrderEvent> ringBuffer;

    public OrderEventProducer(RingBuffer<OrderEvent> ringBuffer) {
        this.ringBuffer = ringBuffer;
    }

    // 生产者向 ringBuffer 中生产消息
    public void sendData(ByteBuffer data) {
        // 1. 生产者先从 ringBuffer 拿到可用的序号
        long sequence = ringBuffer.next();
        try {
            // 2.根据这个序号找到具体的 OrderEvent 元素, 此时获取到的 OrderEvent 对象是一个没有被赋值的空对象
            OrderEvent event = ringBuffer.get(sequence);
            // 3. 设置订单价格
            event.setValue(data.getLong(0));
        } catch (Exception e) {
            e.printStackTrace();
        } finally {
            // 4. 提交发布操作
            ringBuffer.publish(sequence);
        }
    }
}
```



测试类：

```java
public class Main {
    public static void main(String[] args) {
        // 初始化一些参数
        OrderEventFactory orderEventFactory = new OrderEventFactory();
        int ringBufferSize = 8;
        ExecutorService executor = Executors.newFixedThreadPool(Runtime.getRuntime().availableProcessors());
        /**
         * 参数说明：
         * eventFactory:消息(event)工厂对象
         * ringBufferSize: 容器的长度
         * executor:线程池，建议使用自定义的线程池，线程上限。
         * ProducerType:单生产者或多生产者
         * waitStrategy:等待策略
         */
        // 1. 实例化disruptor对象
        Disruptor<OrderEvent> disruptor = new Disruptor<OrderEvent>(
                orderEventFactory,
                ringBufferSize,
                executor,
                ProducerType.SINGLE,
                new BlockingWaitStrategy());
        // 2. 向 Disruptor 中添加消费者，消费者监听到 Disruptor 的 RingBuffer 中有数据了，就会进行消费
        disruptor.handleEventsWith(new OrderEventHandler());
        // 3. 启动disruptor
        disruptor.start();
        // 4. 拿到存放数据的容器：RingBuffer
        RingBuffer<OrderEvent> ringBuffer = disruptor.getRingBuffer();
        // 5. 创建生产者
        OrderEventProducer producer = new OrderEventProducer(ringBuffer);
        // 6. 通过生产者向容器 RingBuffer 中存放数据
        ByteBuffer bb = ByteBuffer.allocate(8);
        for (long i = 0; i < 100; i++) {
            bb.putLong(0, i);
            producer.sendData(bb);
        }

        // 7.关闭
        disruptor.shutdown();
        executor.shutdown();
    }
}

```





### Disruptor 多生产者和多消费者实战



定义消费者，用于从 ringBuffer 中消费订单：

```java
public class ConsumerHandler implements WorkHandler<Order> {

    // 每个消费者有自己的id
    private String comsumerId;

    // 计数统计，多个消费者，所有的消费者总共消费了多个消息。
    private static AtomicInteger count = new AtomicInteger(0);

    private Random random = new Random();

    public ConsumerHandler(String comsumerId) {
        this.comsumerId = comsumerId;
    }

    // 当生产者发布一个 sequence，ringbuffer 中一个序号，里面生产者生产出来的消息，生产者最后publish发布序号
    // 消费者会监听，如果监听到，就会ringbuffer去取出这个序号，取到里面消息
    @Override
    public void onEvent(Order event) throws Exception {
        // 模拟消费者处理消息的耗时，设定1-4毫秒之间
        TimeUnit.MILLISECONDS.sleep(1 * random.nextInt(5));
        System.out.println("当前消费者:" + this.comsumerId + ", 消费信息 ID:" + event.getId());
        // count 计数器增加 +1，表示消费了一个消息
        count.incrementAndGet();
    }

    // 返回所有消费者总共消费的消息的个数。
    public int getCount() {
        return count.get();
    }
}
```



定义订单：

```java
@Data
public class Order {

    private String id;

    private String name;

    private double price;

    public Order() {
    }
}
```



定义生产者，用于向 ringBuffer 中生产订单：

```java
public class Producer {
    private RingBuffer<Order> ringBuffer;

    // 为生产者绑定 ringBuffer
    public Producer(RingBuffer<Order> ringBuffer) {
        this.ringBuffer = ringBuffer;
    }

    // 发送数据
    public void sendData(String uuid) {
        // 1. 获取到可用sequence
        long sequence = ringBuffer.next();
        try {
            Order order = ringBuffer.get(sequence);
            order.setId(uuid);
        } finally {
            // 2. 发布序号
            ringBuffer.publish(sequence);
        }
    }
}
```



测试类：

```java
public class TestMultiDisruptor {
    public static void main(String[] args) throws InterruptedException {
        // 1. 创建 RingBuffer，Disruptor 包含 RingBuffer
        RingBuffer<Order> ringBuffer = RingBuffer.create(ProducerType.MULTI, // 多生产者
                new EventFactory<Order>() {
                    @Override
                    public Order newInstance() {
                        return new Order();
                    }
                }, 1024 * 1024, new YieldingWaitStrategy());
        // 2. 创建 ringBuffer 屏障
        SequenceBarrier sequenceBarrier = ringBuffer.newBarrier();
        // 3. 创建多个消费者数组
        ConsumerHandler[] consumers = new ConsumerHandler[10];
        for (int i = 0; i < consumers.length; i++) {
            consumers[i] = new ConsumerHandler("C" + i);
        }
        // 4. 构建多消费者工作池
        WorkerPool<Order> workerPool = new WorkerPool<Order>(ringBuffer, sequenceBarrier, new EventExceptionHandler(), consumers);
        // 5. 设置多个消费者的 sequence 序号，用于单独统计消费者的消费进度。消费进度让RingBuffer知道
        ringBuffer.addGatingSequences(workerPool.getWorkerSequences());
        // 6. 启动 workPool
        workerPool.start(Executors.newFixedThreadPool(5)); // 在实际开发，自定义线程池。
        //
        final CountDownLatch latch = new CountDownLatch(1);
        // 100 个生产者向 ringBuffer 生产数据，每个生产者发送 100 个数据，共 10000 个数据
        for (int i = 0; i < 100; i ++) {
            final Producer producer = new Producer(ringBuffer);
            new Thread(new Runnable() {
                @Override
                public void run() {
                    try {
                        // 先等待创建完 100 个生产者之后，再发送数据
                        latch.await();
                    } catch (Exception e) {
                        e.printStackTrace();
                    }
                    // 每个生产者发送 100 个数据
                    for (int j = 0; j < 100; j ++) {
                        producer.sendData(UUID.randomUUID().toString());
                    }
                }
            }).start();
        }
        // 把所有线程都创建完
        TimeUnit.SECONDS.sleep(2);
        // 唤醒线程让生产者开始发送数据，开始运行100个线程
        latch.countDown();
        // 等待数据发送完毕
        TimeUnit.SECONDS.sleep(10);
        System.out.println("任务总数:" + consumers[0].getCount());
    }

    static class EventExceptionHandler implements ExceptionHandler<Order> {
        //消费时出现异常
        @Override
        public void handleEventException(Throwable throwable, long l, Order order) {
        }

        //启动时出现异常
        @Override
        public void handleOnStartException(Throwable throwable) {
        }

        //停止时出现异常
        @Override
        public void handleOnShutdownException(Throwable throwable) {
        }
    }
}
```





### Disruptor 与 Netty 结合大幅提高数据处理性能

使用 Netty 接收处理数据时，不要在工作线程上进行处理，降低 Netty 性能，可以使用异步机制，通过线程池来处理，异步处理的话，就是用 Disruptor 来作为任务队列即可

即在 Netty 收到处理数据请求时，封装成一个事件，向 Disruptor 中推送，再通过多消费者来进行处理，可以提升 Netty 处理数据时的性能，流程图如下（绿色部分为通过 Disruptor 优化部分）：

![1702042564713](https://11laile-note-img.oss-cn-beijing.aliyuncs.com/1702042564713.png)





